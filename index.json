[{"description": "", "objectID": "https://blog.threeq.me/post/articles/%E5%B0%8F%E7%99%BD%E5%AD%A6sql/1-install-tools/", "tags": ["数据库", "SQL"], "title": "小白学 SQL 第一天：环境搭建", "uri": "https://blog.threeq.me/post/articles/%E5%B0%8F%E7%99%BD%E5%AD%A6sql/1-install-tools/", "content": "《小白学 SQL》第一天\n本篇文章是《小白学 SQL》系列的开篇，也是学习的第一天。这个系列的文章是之前的学习笔记整理，同时再加入我自己在使用使用的一些使用经验，属于比较初级的知识整理，适合小白用户（初学者和刚入门）。\n数据库管理系统（DBMS）是 IT 从业者必备工具之一，你能在市面上看到的任何一个软件系统，在后面支持的一定有它的身影。 而这里面关系型数据库管理系统（RDBMS） 目前暂居了绝大部分，操作 RDBMS 的基础就是今天我们要开始学习的 SQL（结构化查询语言），所以我们有必要针对 SQL 进行系统全面的学习。\n作为学习的第一天我们将从搭建环境开始，今天实践涉及到的工具有：\n MySQL Docker ConEmuSetup（windows 版本命令行工具，Linux 和 Mac 不需要） Navicat  \n工具选择和说明 可能大家有些奇怪，为什么这里会选用 Docker，这个和我们 SQL 完全没有关系。这里 Docker 确实和我们学习的 SQL 完全没有关系，但就我个人使用来说 ：\n一、docker 作为基础环境，在上面安装 MySQL 服务比我们在自己裸机上装 MySQL 方便得多，并且不易且不怕出错；\n二、目前整个 IT 行业容器化正在如火如荼的进行，这个是未来不可逆转的趋势，Dcoker 正式这个大军里面的主力军；\n三、MySQL 安装跨平台化，使用 Docker 过后你在任何一个系统里面（Windows、Linux、Mac OS）安装 MySQL 操作都是完全一样的\n基于以上三点原因，所以这里我选择了 Docker 作为数据库运行基础环境。\n软件作用：\n   软件 作用说明     Docker 提供跨平台的软件运行基础环境   MySQL 最常用的 RDBMS 之一，作为我们学习 SQL 的数据库服务器   Navicat 一个被广泛使用的数据库客户端，作为我们主要的 SQL 编辑器   ConEmuSetup 一个 Window 命令行终端（Linux、Mac 使用自带的足以）    安装 Windows 安装 ConEmuSetup  到 ConEmuSetup 下载页面 现在对应软件版本 然后一路 “Next” 就好  Docker 安装 Docker 这里我们使用 Community Edition 版本，请到这里下载：下载地址。\n 对于 Windows 版和 Mac 版，下载下来后双击文件运行，剩下的几乎就是一路 &ldquo;Next&rdquo; 点下去就完了，最后双击桌面图标启动 Docker 服务，这里就不在说明了 对于 Linux 版本，由于不同发行版的需求不同，安装步骤略有不同，但是基本也和常用软件安装差不多，并且官方文档也和齐全这里就直接放官方的安装连接地址了（是英文的哟，如果有好的中文教程推荐，请留言我尽快放上来）: Ubuntu CentOS Fedora Debian  加速器配置：Windows、Mac 对于 Docker 安装完成过后，国内用户还有一步需要操作：指定 docker 加速器（原因不多说）。Windows 和 Mac 系统具体操作如下：\n 找到 Docker 运行系统托盘图片，右击打开菜单如下    点击 Preferences 菜单，打开设置界面如下   点击 Daemon 标签项，再 Rgistry mirrors 中输入镜像加速器网址 https://docker.mirrors.ustc.edu.cn。如下图  对于 Linux 系统配置需要修改相关配置文件，不同系统版本有所不同。\n加速器配置：Ubuntu 14.04、Debian 7 Wheezy 对于使用 upstart 的系统而言，编辑 /etc/default/docker 文件，在其中的 DOCKER_OPTS中配置加速器地址：\nDOCKER_OPTS=&quot;--registry-mirror=https://docker.mirrors.ustc.edu.cn&quot;  重启 Docker 服务：\n$ sudo service docker restart  加速器配置：Ubuntu 16.04+、Debian 8+、CentOS 7 对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）\n{ &quot;registry-mirrors&quot;: [ &quot;https://docker.mirrors.ustc.edu.cn&quot; ] }   注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。\n 重启 Docker 服务：\n$ sudo systemctl daemon-reload $ sudo systemctl restart docker  检查加速器是否生效 打开终端（命令行工具）输入 docker info 命令，如果从结果中看到了如下内容，说明配置成功。\nRegistry Mirrors: https://docker.mirrors.ustc.edu.cn/  其他可用的加速服务有很多，这里列举几个方便大家查找：\n Docker 官方提供的中国 registry mirror DaoCloud 加速器 阿里云加速器  MySQL 服务安装 在安装完成 Docker 过后，MySQL 服务的安装就很简单了。在你的终端命令行里面输入如下命令启动 MySQL 服务：\n$ docker run --name sql-learn -e MYSQL_ROOT_PASSWORD=toor -p3306:3306 -d mysql  查看 MySQL 服务运行状态\n$ docker ps  这里不要被命令吓着了，Docker 本身的命令不少，包括以后的所有操作，我们总共用到 docker 命令就4、5个。这里先列出来，大家可以操作一下\n$ docker run --name sql-learn -e MYSQL_ROOT_PASSWORD=toor -p3306:3306 -d mysql # 创建一个名为 sql-learn MySQL 容器 $ docker ps # 查看容器运行状态 $ docker stop sql-learn # 停止 sql-learn 容器 $ docker rm sql-learn # 删除 sql-learn 容器，必须先停止  Navicat 安装 安装和 ConEmuSetup 类似\n 到 Navicat 下载页面 现在对应软件版本。推荐 Navicat Premium 然后一路 “Next” 就好  验证环境安装完成  双击桌面 “Navicat” 应用图标，打开 Navicat 软件  ​  点击 “链接” 增加到 sql-learn 的数据库链接。输入截图里面的内容，这里密码输入 toor ，点击 “Test Connection” 出现绿点没有错误表示成功，如下图   双击 “左边导航列表” 里的 sql-learn 得到如下结果   创建一个用于我们以后学习使用的数据库。点击 “New Query” 新建一个查询窗口  输入一下 SQL 语句\ncreate database `sql-learn` default charset=utf8mb4;  点击执行得到如下结果，表示成功\n支持我们的环境安装和验证全部结束。\n总结 我们学习一下几点：\n 如何安装 Docker 服务\n 如何在 Docker 里面启动 MySQL 服务器\n   docker run --name sql-learn -e MYSQL_ROOT_PASSWORD=toor -p3306:3306 -d mysql # 无 sql-learn 容器时 或 docker start sql-learn # 已有 sql-learn 容器时   我们在使用数据库系统的时候需要一个数据库服务器（这里是 MySQL），还需要一个数据库客户端（这里是 Navicat）\n 在链接 MySQL 服务器之前需要先启动 MySQL 服务器\n 在连接一个 MySQL 服务器是需要提供的基本信息有：服务器 IP、服务器端口、用户名、密码\n ", "content_s": "《 小白学   SQL 》 第一 一天 第一天 \n 本篇 文章 是 《 小白学   SQL 》 系列 的 开篇 ， 也 是 学习 的 第一 一天 第一天 。 这个 系列 的 文章 是 之前 的 学习 笔记 整理 ， 同时 再 加入 我 自己 在 使用 使用 的 一些 使用 经验 ， 属于 比较 初级 的 知识 整理 ， 适合 小白 用户 （ 初学 学者 初学者 和 刚 入门 ） 。 \n 数据 据库 数据库 管理 系统 管理系 管理系统 （ DBMS ） 是   IT   从业 业者 从业者 必备 工具 之一 ， 你 能 在 市面 面上 市面上 看到 的 任何 一个 软件 系统 软件系统 ， 在 后面 支持 的 一定 有 它 的 身影 。   而 这 里面 关系 型 数据 据库 数据库 管理 系统 管理系 管理系统 （ RDBMS ）   目前 暂居 了 绝大 大部 部分 大部分 绝大部分 ， 操作   RDBMS   的 基础 就是 今天 我们 要 开始 学习 的   SQL （ 结构 结构化 查询 语言 查询语言 ） ， 所以 我们 有 必要 针对   SQL   进行 系统 全面 的 学习 。 \n 作为 学习 的 第一 一天 第一天 我们 将 从 搭建 环境 开始 ， 今天 实践 涉及 到 的 工具 有 ： \n   MySQL   Docker   ConEmuSetup （ windows   版本 命令 命令行 工具 ， Linux   和   Mac   不 需要 ）   Navicat     \n 工具 选择 和 说明   可能 大家 有些 奇怪 ， 什么 为什么 这里 会 选用   Docker ， 这个 和 我们   SQL   完全 没有 关系 。 这里   Docker   确实 和 我们 学习 的   SQL   完全 没有 关系 ， 但 就 我 个人 使用 来说   ： \n 一 、 docker   作为 基础 环境 ， 在 上面 安装   MySQL   服务 比 我们 在 自己 裸机 上装   MySQL   方便 得 多 ， 并且 不易 且 不怕 出错 ； \n 二 、 目前 整个   IT   行业 容器 化 正在 如火如荼 的 进行 ， 这个 是 未来 不可 可逆 逆转 不可逆转 的 趋势 ， Dcoker   正式 这个 大军 里面 的 主力 主力军 ； \n 三 、 MySQL   安装 平台 跨平台 化 ， 使用   Docker   过后 你 在 任何 一个 系统 里面 （ Windows 、 Linux 、 Mac   OS ） 安装   MySQL   操作 都 是 完全 一样 的 \n 基于 以上 三点 原因 ， 所以 这里 我 选择 了   Docker   作为 数据 据库 数据库 运行 基础 环境 。 \n 软件 作用 ： \n       软件   作用 说明           Docker   提供 平台 跨平台 的 软件 运行 基础 环境       MySQL   最 常用 的   RDBMS   之一 ， 作为 我们 学习   SQL   的 数据 据库 数据库 服务 务器 服务器       Navicat   一个 被 广泛 使用 的 数据 据库 数据库 客户 客户端 ， 作为 我们 主要 的   SQL   编辑 编辑器       ConEmuSetup   一个   Window   命令 命令行 终端 （ Linux 、 Mac   使用 自带 的 足以 ）         安装   Windows   安装   ConEmuSetup     到   ConEmuSetup   下载 页面   现在 对应 软件 版本   然后 一路   “ Next ”   就 好     Docker   安装   Docker   这里 我们 使用   Community   Edition   版本 ， 请 到 这里 下载 ： 下载 地址 。 \n   对于   Windows   版 和   Mac   版 ， 下载 下来 后 双击 文件 运行 ， 剩下 的 几乎 就是 一路   & ldquo ; Next & rdquo ;   点 下去 就 完 了 ， 最后 双击 桌面 图标 桌面图 桌面图标 启动   Docker   服务 ， 这里 就 不 在 说明 了   对于   Linux   版本 ， 由于 不同 发行 发行版 的 需求 不同 ， 安装 步骤 略有 不同 略有不同 ， 但是 基本 也 和 常用 软件 常用软件 安装 不多 差不多 ， 并且 官方 文档 也 和 齐全 这里 就 直接 放 官方 的 安装 连接 地址 了 （ 是 英文 的 哟 ， 如果 有 好 的 中文 教程 推荐 ， 请 留言 我 尽快 放上 上来 放上来 ） :   Ubuntu   CentOS   Fedora   Debian     加速 加速器 配置 ： Windows 、 Mac   对于   Docker   安装 完成 过后 ， 国内 用户 还有 一步 需要 操作 ： 指定   docker   加速 加速器 （ 原因 不多 说 ） 。 Windows   和   Mac   系统 具体 体操 操作 具体操作 如下 ： \n   找到   Docker   运行 系统 托盘 系统托盘 图片 ， 右击 打开 菜单 如下         点击   Preferences   菜单 ， 打开 设置 界面 如下       点击   Daemon   标签 项 ， 再   Rgistry   mirrors   中 输入 镜像 加速 加速器 网址   https : / / docker . mirrors . ustc . edu . cn 。 如下 图     对于   Linux   系统 统配 配置 系统配 系统配置 需要 修改 相关 配置 文件 配置文件 ， 不同 系统 版本 有所 不同 有所不同 。 \n 加速 加速器 配置 ： Ubuntu   14.04 、 Debian   7   Wheezy   对于 使用   upstart   的 系统 而言 ， 编辑   / etc / default / docker   文件 ， 在 其中 的   DOCKER _ OPTS 中 配置 加速 加速器 地址 ： \n DOCKER _ OPTS = & quot ; - - registry - mirror = https : / / docker . mirrors . ustc . edu . cn & quot ;     重启   Docker   服务 ： \n $   sudo   service   docker   restart     加速 加速器 配置 ： Ubuntu   16.04 + 、 Debian   8 + 、 CentOS   7   对于 使用   systemd   的 系统 ， 请 在   / etc / docker / daemon . json   中 写入 如下 内容 （ 如果 文件 不 存在 请 新建 该 文件 ） \n {   & quot ; registry - mirrors & quot ; :   [   & quot ; https : / / docker . mirrors . ustc . edu . cn & quot ;   ]   }       注意 ， 一定 要 保证 该 文件 符合   json   规范 ， 否则   Docker   将 不能 启动 。 \n   重启   Docker   服务 ： \n $   sudo   systemctl   daemon - reload   $   sudo   systemctl   restart   docker     检查 加速 加速器 是否 生效   打开 终端 （ 命令 命令行 工具 ） 输入   docker   info   命令 ， 如果 从 结果 中 看到 了 如下 内容 ， 说明 配置 成功 。 \n Registry   Mirrors :   https : / / docker . mirrors . ustc . edu . cn /     其他 可用 的 加速 服务 有 很多 ， 这里 列举 几个 方便 大家 查找 ： \n   Docker   官方 提供 的 中国   registry   mirror   DaoCloud   加速 加速器   阿里 云 加速 加速器     MySQL   服务 安装   在 安装 完成   Docker   过后 ， MySQL   服务 的 安装 就 很 简单 了 。 在 你 的 终端 命令 命令行 里面 输入 如下 命令 启动   MySQL   服务 ： \n $   docker   run   - - name   sql - learn   - e   MYSQL _ ROOT _ PASSWORD = toor   - p3306 : 3306   - d   mysql     查看   MySQL   服务 运行 状态 \n $   docker   ps     这里 不要 被 命令 吓 着 了 ， Docker   本身 的 命令 不少 ， 包括 以后 的 所有 操作 ， 我们 总共 用到   docker   命令 就 4 、 5 个 。 这里 先列 出来 ， 大家 可以 操作 一下 \n $   docker   run   - - name   sql - learn   - e   MYSQL _ ROOT _ PASSWORD = toor   - p3306 : 3306   - d   mysql   #   创建 一个 名为   sql - learn   MySQL   容器   $   docker   ps   #   查看 容器 运行 状态   $   docker   stop   sql - learn   #   停止   sql - learn   容器   $   docker   rm   sql - learn   #   删除   sql - learn   容器 ， 必须 先 停止     Navicat   安装   安装 和   ConEmuSetup   类似 \n   到   Navicat   下载 页面   现在 对应 软件 版本 。 推荐   Navicat   Premium   然后 一路   “ Next ”   就 好     验证 环境 安装 完成     双击 桌面   “ Navicat ”   应用 图标 ， 打开   Navicat   软件     ​     点击   “ 链接 ”   增加 到   sql - learn   的 数据 据库 数据库 链接 。 输入 截图 里面 的 内容 ， 这里 密码 输入   toor   ， 点击   “ Test   Connection ”   出现 绿点 没有 错误 表示 成功 ， 如下 图       双击   “ 左边 导航 列表 ”   里 的   sql - learn   得到 如下 结果       创建 一个 用于 我们 以后 学习 使用 的 数据 据库 数据库 。 点击   “ New   Query ”   新建 一个 查询 窗口     输入 一下   SQL   语句 \n create   database   ` sql - learn `   default   charset = utf8mb4 ;     点击 执行 得到 如下 结果 ， 表示 成功 \n 支持 我们 的 环境 安装 和 验证 全部 结束 。 \n 总结   我们 学习 一下 几点 ： \n   如何 安装   Docker   服务 \n   如何 在   Docker   里面 启动   MySQL   服务 务器 服务器 \n       docker   run   - - name   sql - learn   - e   MYSQL _ ROOT _ PASSWORD = toor   - p3306 : 3306   - d   mysql   #   无   sql - learn   容器 时   或   docker   start   sql - learn   #   已有   sql - learn   容器 时       我们 在 使用 数据 据库 系统 数据库 数据库系统 的 时候 需要 一个 数据 据库 数据库 服务 务器 服务器 （ 这里 是   MySQL ） ， 还 需要 一个 数据 据库 数据库 客户 客户端 （ 这里 是   Navicat ） \n   在 链接   MySQL   服务 务器 服务器 之前 需要 先 启动   MySQL   服务 务器 服务器 \n   在 连接 一个   MySQL   服务 务器 服务器 是 需要 提供 的 基本 信息 有 ： 服务 务器 服务器   IP 、 服务 务器 服务器 服务器端 口 、 用户 户名 用户名 、 密码 \n  ", "title_s": "小白学   SQL   第一 一天 第一天 ： 环境 搭建"}, {"description": "", "objectID": "https://blog.threeq.me/post/db/mysql-slow-query-analyse/", "tags": ["Mysql", "数据库", "查询优化", "percona", "pt-query-digest"], "title": "mysql 查询优化：慢查询分析工具 pt-query-digest", "uri": "https://blog.threeq.me/post/db/mysql-slow-query-analyse/", "content": "在系统刚上线的时候，经常会出现慢 SQL 的情况，并且有时候系统会在特定的时间点变慢。这个时候的慢 SQL 查询语句往往是大量出现，MySQL 的慢查询日志文件也会比较大。这个时候我们往往需要从哪些查询最多、耗时最长的 sql 开始优化，以提升我们的处理效益。这个时候就需要我们能对慢日志进行统计分析，在上 M ，甚至 几十 M 的日志文件里面使用手工的方式明显是不可能的，这个时候就需要有专门的统计分析工具来帮我们做统计、分析哪些慢查询日志。percona-toolkit 就是一个提供统计和分析的工具集，这里重点介绍里面的 pt-query-digest 工具。\n\npercona-toolkit 安装 percona-toolkit 首页 文档 下载地址\nmac 安装 可以使用 brew 直接安装\nbrew install percona-toolkit  Linux 安装 详细信息参考 官方安装文档\n源码安装 # 下载源码 wget https://www.percona.com/downloads/percona-toolkit/3.0.8/source/tarball/percona-toolkit-3.0.8.tar.gz # 解压 tar xf percona-toolkit-3.0.8.tar.gz #进入目录安装 cd percona-toolkit-3.0.8 #开始编译安装 perl Makefile.PL make make install #安装完了就有命令了 ll /usr/local/bin/pt-*  pt-query-digest 基本使用 在使用 pt-query-digest 前需要有 MySQL 慢查询日志文件，这里为了大家方便实验提供了一份 MySQL 慢查询日实验数据 供大家下载测试（slow-sql-test.sql.zip 点击我下载，里面包含2018.04.01～2018.04.04 和 2018.04.06 的日志数据）。\n 查看使用帮助  &gt; pt-query-digest --help   默认分析参数  &gt; pt-query-digest slow-sql-test.sql   总体概要信息：\n   信息字段 说明     Exec Time 执行时间   Lock Time 锁时间   Row sent 发送行大小   Row examine 检查行大小   Query size 查询大小   Rank SQL 编号   Query ID 查询 id   Response time sql 总共执行时间 和 时间比例   Calls sql 执行次数   R/Call sql 平均每次执行时间   V/M    Item sql 类型和涉及到的表    单个 SQL 信息：\n ​ 分析结果说明：\n 分析最近一段时间内的慢查询  &gt; pt-query-digest --since=12h slow-sql-test.sql # 最近 12 小时的慢查询   分析指定时间段内的慢查询  &gt; pt-query-digest slow-sql-test.sql --since '2018-04-01 09:30:00' --until '2018-04-02 10:00:00'   分析还有指定特征的慢查询 SQL  &gt; pt-query-digest --filter '$event-&gt;{fingerprint} =~ m/^select/i' slow-sql-test.sql   分析针对某个用户的慢查询  &gt; pt-query-digest --filter '($event-&gt;{member} || &quot;&quot;) =~ m/^root/i' slow-sql-test.sql   ​  pt-query-digest进阶使用 有时候我们会遇到针对慢 SQL 进行长期的跟踪分析，这个时候我们就需要将我们的每次的分析结果进行汇总、对比分析。同时对于部分环境我们是不能直接得到慢 SQL 日志的，这个时候我们可以通过抓取 TCP 协议数据或 binlog 进行分析\n 将分析结果保存到数据库  &gt; pt-query-digest --user=root –password=abc123 --review h=localhost,D=test,t=query_review--create-review-table slow-sql-test.sql   通过抓取 TCP 协议数据分析  &gt; tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txt &gt; pt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log   通过 binlog 日志分析  &gt; mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sql &gt; pt-query-digest --type=binlog mysql-bin000093.sql &gt; slow_report10.log  单条 SQL 优化基本分析 通过上面的方法就可以找出系统里面所有的慢 SQL 语句了，并且在分析报告里面会排好序，剩下的就是我们针对每条 SQL 语句的分析调优工作了。针对 SQL 的具体优化方式内容很多，建议大家系统的学习，后面我也会写一些我常用的方法。这里说一下单条 SQL 的基础分析方法，好让大家有个开头。\n 查看 SQL 执行计划  EXPLAIN select ep_name as '企业名称', count(*) as '企业人数', FROM_UNIXTIME(ep_created/1000, GET_FORMAT(DATE,'ISO')) as '注册时间' from uc_member u left join uc_enterprise e on u.ep_id=e.ep_id where ep_domain='yq.vchangyi.com' and mem_status&lt;3 group by u.ep_id order by 企业人数 desc;\t 对于上面每一列的的意义这里不再详细介绍，有兴趣的同学可以查看 MySQL 文档，或者关注我后续的文章，会有专门介绍。\n 查询 SQL 执行信息  查看 MySQL 语句执行信息需要首先开启 profiling 选线\nset profiling = 1;  然后执行完 SQL 过后使用 show profiles; 语句查看执行 SQL 的记录id\nselect ep_name as '企业名称', count(*) as '企业人数', FROM_UNIXTIME(ep_created/1000, GET_FORMAT(DATE,'ISO')) as '注册时间' from uc_member u left join uc_enterprise e on u.ep_id=e.ep_id where ep_domain='yq.vchangyi.com' and mem_status&lt;3 group by u.ep_id order by 企业人数 desc; show profiles;  使用 show profile 查看 SQL 的执行信息\nshow profile ALL for query 3;  语法格式：\nshow profile [type] for query &lt;query_id&gt;;  如果没有指定 FOR QUERY 则显示最近一条查询的详细信息。type 是可选的，有以下几个选项：\n ALL 显示所有性能信息 BLOCK IO 显示块IO操作的次数 CONTEXT SWITCHES 显示上下文切换次数，不管是主动还是被动 CPU 显示用户CPU时间、系统CPU时间 IPC 显示发送和接收的消息数量 MEMORY [暂未实现] PAGE FAULTS 显示页错误数量 SOURCE 显示源码中的函数名称与位置 SWAPS 显示SWAP的次数 ", "content_s": "在 系统 刚 上线 的 时候 ， 经常 会 出现 慢   SQL   的 情况 ， 并且 有时 时候 有时候 系统 会 在 特定 的 时间 点 变慢 。 这个 时候 的 慢   SQL   查询 语句 往往 是 大量 出现 ， MySQL   的 慢 查询 日志 文件 也 会 比较 大 。 这个 时候 我们 往往 需要 从 哪些 查询 最 多 、 耗时 最长 的   sql   开始 优化 ， 以 提升 我们 的 处理 效益 。 这个 时候 就 需要 我们 能 对 慢 日志 进行 统计 计分 分析 统计分析 ， 在 上   M   ， 甚至   几十   M   的 日志 文件 里面 使用 手工 的 方式 明显 是 不 可能 的 ， 这个 时候 就 需要 有 专门 的 统计 计分 分析 统计分析 工具 来 帮 我们 做 统计 、 分析 哪些 慢 查询 日志 。 percona - toolkit   就是 一个 提供 统计 和 分析 的 工具 工具集 ， 这里 重点 介绍 里面 的   pt - query - digest   工具 。 \n \n percona - toolkit   安装   percona - toolkit   首页   文档   下载 地址 \n mac   安装   可以 使用   brew   直接 安装 \n brew   install   percona - toolkit     Linux   安装   详细 信息 详细信息 参考   官方 安装 文档 \n 源码 安装   #   下载 源码   wget   https : / / www . percona . com / downloads / percona - toolkit / 3.0 . 8 / source / tarball / percona - toolkit - 3.0 . 8 . tar . gz   #   解压   tar   xf   percona - toolkit - 3.0 . 8 . tar . gz   # 进入 目录 安装   cd   percona - toolkit - 3.0 . 8   # 开始 编译 安装   perl   Makefile . PL   make   make   install   # 安装 完 了 就 有 命令 了   ll   / usr / local / bin / pt - *     pt - query - digest   基本 使用   在 使用   pt - query - digest   前 需要 有   MySQL   慢 查询 日志 文件 ， 这里 为了 大家 方便 实验 提供 了 一份   MySQL   慢 查询 日 实验 数据   供 大家 下载 测试 （ slow - sql - test . sql . zip   点击 我 下载 ， 里面 包含 2018.04 . 01 ～ 2018.04 . 04   和   2018.04 . 06   的 日志 数据 ） 。 \n   查看 使用 帮助     & gt ;   pt - query - digest   - - help       默认 分析 参数     & gt ;   pt - query - digest   slow - sql - test . sql       总体 概要 信息 ： \n       信息 字 段   说明           Exec   Time   执行 时间       Lock   Time   锁 时间       Row   sent   发送 行 大小       Row   examine   检查 行 大小       Query   size   查询 大小       Rank   SQL   编号       Query   ID   查询   id       Response   time   sql   总共 执行 时间   和   时间 比例       Calls   sql   执行 次数       R / Call   sql   平均 每次 执行 时间       V / M         Item   sql   类型 和 涉及 到 的 表         单个   SQL   信息 ： \n   ​   分析 结果 说明 ： \n   分析 最近 一段 时间 段时间 一段时间 内 的 慢 查询     & gt ;   pt - query - digest   - - since = 12h   slow - sql - test . sql   #   最近   12   小时 的 慢 查询       分析 指定 时间 时间段 内 的 慢 查询     & gt ;   pt - query - digest   slow - sql - test . sql   - - since   ' 2018 - 04 - 01   09 : 30 : 00 '   - - until   ' 2018 - 04 - 02   10 : 00 : 00 '       分析 还有 指定 特征 的 慢 查询   SQL     & gt ;   pt - query - digest   - - filter   ' $ event - & gt ; { fingerprint }   = ~   m / ^ select / i '   slow - sql - test . sql       分析 针对 某个 用户 的 慢 查询     & gt ;   pt - query - digest   - - filter   ' ( $ event - & gt ; { member }   | |   & quot ; & quot ; )   = ~   m / ^ root / i '   slow - sql - test . sql       ​     pt - query - digest 进阶 使用   有时 时候 有时候 我们 会 遇到 针对 慢   SQL   进行 长期 的 跟踪 分析 ， 这个 时候 我们 就 需要 将 我们 的 每次 的 分析 结果 进行 汇总 、 对比 分析 。 同时 对于 部分 环境 我们 是 不能 直接 得到 慢   SQL   日志 的 ， 这个 时候 我们 可以 通过 抓取   TCP   协议 数据 或   binlog   进行 分析 \n   将 分析 结果 保存 到 数据 据库 数据库     & gt ;   pt - query - digest   - - user = root   – password = abc123   - - review   h = localhost , D = test , t = query _ review - - create - review - table   slow - sql - test . sql       通过 抓取   TCP   协议 数据 分析 数据分析     & gt ;   tcpdump   - s   65535   - x   - nn   - q   - tttt   - i   any   - c   1000   port   3306   & gt ;   mysql . tcp . txt   & gt ;   pt - query - digest   - - type   tcpdump   mysql . tcp . txt & gt ;   slow _ report9 . log       通过   binlog   日志 分析     & gt ;   mysqlbinlog   mysql - bin.000093   & gt ;   mysql - bin000093 . sql   & gt ;   pt - query - digest   - - type = binlog   mysql - bin000093 . sql   & gt ;   slow _ report10 . log     单条   SQL   优化 基本 分析   通过 上面 的 方法 就 可以 找出 系统 里面 所有 的 慢   SQL   语句 了 ， 并且 在 分析 报告 里面 会排 好序 ， 剩下 的 就是 我们 针对 每条   SQL   语句 的 分析 调优 工作 了 。 针对   SQL   的 具体 优化 方式 内容 很多 ， 建议 大家 系统 的 学习 ， 后面 我 也 会 写 一些 我 常用 的 方法 。 这里 说 一下 单条   SQL   的 基础 分析 方法 分析方法 ， 好 让 大家 有个 开头 。 \n   查看   SQL   执行 计划     EXPLAIN   select   ep _ name   as   ' 企业 名称 ' ,   count ( * )   as   ' 企业 人数 ' ,   FROM _ UNIXTIME ( ep _ created / 1000 ,   GET _ FORMAT ( DATE , ' ISO ' ) )   as   ' 注册 时间 '   from   uc _ member   u   left   join   uc _ enterprise   e   on   u . ep _ id = e . ep _ id   where   ep _ domain = ' yq . vchangyi . com '   and   mem _ status & lt ; 3   group   by   u . ep _ id   order   by   企业 人数   desc ; \t   对于 上面 每 一列 的 的 意义 这里 不再 详细 介绍 ， 有 兴趣 的 同学 可以 查看   MySQL   文档 ， 或者 关注 我 后续 的 文章 ， 会 有 专门 介绍 。 \n   查询   SQL   执行 信息     查看   MySQL   语句 执行 信息 需要 首先 开启   profiling   选线 \n set   profiling   =   1 ;     然后 执行 完   SQL   过后 使用   show   profiles ;   语句 查看 执行   SQL   的 记录 id \n select   ep _ name   as   ' 企业 名称 ' ,   count ( * )   as   ' 企业 人数 ' ,   FROM _ UNIXTIME ( ep _ created / 1000 ,   GET _ FORMAT ( DATE , ' ISO ' ) )   as   ' 注册 时间 '   from   uc _ member   u   left   join   uc _ enterprise   e   on   u . ep _ id = e . ep _ id   where   ep _ domain = ' yq . vchangyi . com '   and   mem _ status & lt ; 3   group   by   u . ep _ id   order   by   企业 人数   desc ;   show   profiles ;     使用   show   profile   查看   SQL   的 执行 信息 \n show   profile   ALL   for   query   3 ;     语法 格式 ： \n show   profile   [ type ]   for   query   & lt ; query _ id & gt ; ;     如果 没有 指定   FOR   QUERY   则 显示 最近 一条 查询 的 详细 信息 详细信息 。 type   是 可选 的 ， 有 以下 几个 选项 ： \n   ALL   显示 所有 性能 信息   BLOCK   IO   显示 块 IO 操作 的 次数   CONTEXT   SWITCHES   显示 上下 下文 上下文 切换 次数 ， 不管 是 主动 还是 被动   CPU   显示 用户 CPU 时间 、 系统 CPU 时间   IPC   显示 发送 和 接收 的 消息 数量   MEMORY   [ 暂未 实现 ]   PAGE   FAULTS   显示 页 错误 数量   SOURCE   显示 源码 中 的 函数 名称 与 位置   SWAPS   显示 SWAP 的 次数  ", "title_s": "mysql   查询 优化 ： 慢 查询 分析 工具   pt - query - digest"}, {"description": "", "objectID": "https://blog.threeq.me/post/db/mysql-sql-index-analyse-tool/", "tags": ["Mysql", "数据库", "查询优化"], "title": "mysql 查询优化：索引优化", "uri": "https://blog.threeq.me/post/db/mysql-sql-index-analyse-tool/", "content": "我们在产品中使用 MySQL 数据库的时候，肯定会用到索引的，或是在前期建立一些初始索引，或是在后期 SQL 优化的时候根据系统运行状态逐渐增加索引。不论是以什么方式建立的索引，他们都会影响我们对数据库做的操作，并且是对我们所有的数据操作都有影响，包括 增加、删除、修改、查询、统计 操作。这时如果线上有部分索引在系统升级已经失效了，我们怎么知道，怎么及时的排查和删除，需要我们持续的跟踪和分析。今天我就介绍几款针对线上数据库索引的分析工具。\n pt-index-usage userstat check-unused-keys  \n1. pt-index-usage pt-index-usage 从日志里面读取查询，并且分析它们是如何使用索引的。它需要 MySQL 的慢查询日志，在实际分析中我们可以讲 MySQL 的慢查询参数设置为 0 ，这样就可以得到所有的执行 SQL。\npt-index-uage 的安装请参考 [mysql 查询优化：慢查询分析工具 pt-query-digest]\n使用：\n&gt; pt-index-usage [OPTIONS] [FILES]  分析 slow.log 的所有查询语句，并打印报告\n&gt; pt-index-usage /path/to/slow.log --host localhost  不打印报告，同时把分析后的结果存入 percona 数据库\n&gt; pt-index-usage slow.log --no-report --save-results-database percona  详情参考 pt-index-uage 官方文档 和 使用手册 [pt-index-uage --help]\n2. userstat MySQL 设置：\nmysql&gt; SET GLOBAL userstat=ON; mysql&gt; SET GLOBAL `thread_statistics`=1; mysql&gt; SHOW GLOBAL VARIABLES LIKE &quot;userstat&quot;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | userstat | ON | +---------------+-------+ 1 row in set (0.00 sec)  查询客户端连接信息\nmysql&gt; SELECT * FROM INFORMATION_SCHEMA.CLIENT_STATISTICS\\G *************************** 1. row *************************** CLIENT: 10.1.12.30 TOTAL_CONNECTIONS: 20 CONCURRENT_CONNECTIONS: 0 CONNECTED_TIME: 0 BUSY_TIME: 93 CPU_TIME: 48 BYTES_RECEIVED: 5031 BYTES_SENT: 276926 BINLOG_BYTES_WRITTEN: 217 ROWS_FETCHED: 81 ROWS_UPDATED: 0 TABLE_ROWS_READ: 52836023 SELECT_COMMANDS: 26 UPDATE_COMMANDS: 1 OTHER_COMMANDS: 145 COMMIT_TRANSACTIONS: 1 ROLLBACK_TRANSACTIONS: 0 DENIED_CONNECTIONS: 0 LOST_CONNECTIONS: 0 ACCESS_DENIED: 0 EMPTY_QUERIES: 0 TOTAL_SSL_CONNECTIONS: 0  查询索引使用信息：\nmysql&gt; SELECT * FROM INFORMATION_SCHEMA.INDEX_STATISTICS WHERE TABLE_NAME='tables_priv'; +--------------+-----------------------+--------------------+-----------+ | TABLE_SCHEMA | TABLE_NAME | INDEX_NAME | ROWS_READ | +--------------+-----------------------+--------------------+-----------+ | mysql | tables_priv | PRIMARY | 2 | +--------------+-----------------------+--------------------+-----------+  查询表的使用信息：\nmysql&gt; SELECT * FROM INFORMATION_SCHEMA.TABLE_STATISTICS WHERE TABLE_NAME=``tables_priv``; +--------------+-------------------------------+-----------+--------------+------------------------+ | TABLE_SCHEMA | TABLE_NAME | ROWS_READ | ROWS_CHANGED | ROWS_CHANGED_X_INDEXES | +--------------+-------------------------------+-----------+--------------+------------------------+ | mysql | tables_priv | 2 | 0 | 0 | +--------------+-------------------------------+-----------+--------------+------------------------+  具体详情请参考文档：https://www.percona.com/doc/percona-server/5.7/diagnostics/user_stats.html\n3. check-unused-keys check-unused-keys 是 Ryan Lowe 编写的基于 userstat 的一个 perl 脚本。能够比较方便输出需要删除的索引。\n下载地址：https://code.google.com/archive/p/check-unused-keys/downloads / 备份地址\nMySQL 设置：\nmysql&gt; SET GLOBAL userstat=ON; mysql&gt; SET GLOBAL `thread_statistics`=1; mysql&gt; SHOW GLOBAL VARIABLES LIKE &quot;userstat&quot;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | userstat | ON | +---------------+-------+ 1 row in set (0.00 sec)  语法：\n&gt; ./check-unused-keys --help  使用：\n./check-unused-keys --host=127.0.0.1 --username=root --password=toor --port=3306 --create-alter  参考：\nhttps://www.percona.com/blog/2009/06/26/check-unused-keys-a-tool-to-interact-with-index_statistics/\nhttps://www.percona.com/blog/2008/09/12/googles-user_statistics-v2-port-and-changes/\nhttps://code.google.com/archive/p/check-unused-keys/\nhttps://www.percona.com/blog/2012/12/05/quickly-finding-unused-indexes-and-estimating-their-size/\nhttps://yq.aliyun.com/articles/308518\n", "content_s": "我们 在 产品 中 使用   MySQL   数据 据库 数据库 的 时候 ， 肯定 会 用到 索引 的 ， 或是 在 前期 建立 一些 初始 索引 ， 或是 在 后期   SQL   优化 的 时候 根据 系统 运行 状态 逐渐 增加 索引 。 不论 不论是 以 什么 方式 建立 的 索引 ， 他们 都 会 影响 我们 对 数据 据库 数据库 做 的 操作 ， 并且 是 对 我们 所有 的 数据 操作 都 有 影响 ， 包括   增加 、 删除 、 修改 、 查询 、 统计   操作 。 这时 如果 线上 有 部分 索引 在 系统 升级 系统升级 已经 失效 了 ， 我们 怎么 知道 ， 怎么 及时 的 排查 和 删除 ， 需要 我们 持续 的 跟踪 和 分析 。 今天 我 就 介绍 几款 针对 线上 数据 据库 数据库 索引 的 分析 工具 。 \n   pt - index - usage   userstat   check - unused - keys     \n 1 .   pt - index - usage   pt - index - usage   从 日志 里面 读取 查询 ， 并且 分析 它们 是 如何 使用 索引 的 。 它 需要   MySQL   的 慢 查询 日志 ， 在 实际 分析 中 我们 可以 讲   MySQL   的 慢 查询 参数 设置 参数设置 为   0   ， 这样 就 可以 得到 所有 的 执行   SQL 。 \n pt - index - uage   的 安装 请 参考   [ mysql   查询 优化 ： 慢 查询 分析 工具   pt - query - digest ] \n 使用 ： \n & gt ;   pt - index - usage   [ OPTIONS ]   [ FILES ]     分析   slow . log   的 所有 查询 语句 ， 打印 并打印 报告 \n & gt ;   pt - index - usage   / path / to / slow . log   - - host   localhost     不 打印 报告 ， 同时 把 分析 后 的 结果 存入   percona   数据 据库 数据库 \n & gt ;   pt - index - usage   slow . log   - - no - report   - - save - results - database   percona     详情 参考   pt - index - uage   官方 文档   和   使用 手册 使用手册   [ pt - index - uage   - - help ] \n 2 .   userstat   MySQL   设置 ： \n mysql & gt ;   SET   GLOBAL   userstat = ON ;   mysql & gt ;   SET   GLOBAL   ` thread _ statistics ` = 1 ;   mysql & gt ;   SHOW   GLOBAL   VARIABLES   LIKE   & quot ; userstat & quot ; ;   + - - - - - - - - - - - - - - - + - - - - - - - +   |   Variable _ name   |   Value   |   + - - - - - - - - - - - - - - - + - - - - - - - +   |   userstat   |   ON   |   + - - - - - - - - - - - - - - - + - - - - - - - +   1   row   in   set   ( 0.00   sec )     查询 客户 客户端 连接 信息 \n mysql & gt ;   SELECT   *   FROM   INFORMATION _ SCHEMA . CLIENT _ STATISTICS \\ G   * * * * * * * * * * * * * * * * * * * * * * * * * * *   1 .   row   * * * * * * * * * * * * * * * * * * * * * * * * * * *   CLIENT :   10.1 . 12.30   TOTAL _ CONNECTIONS :   20   CONCURRENT _ CONNECTIONS :   0   CONNECTED _ TIME :   0   BUSY _ TIME :   93   CPU _ TIME :   48   BYTES _ RECEIVED :   5031   BYTES _ SENT :   276926   BINLOG _ BYTES _ WRITTEN :   217   ROWS _ FETCHED :   81   ROWS _ UPDATED :   0   TABLE _ ROWS _ READ :   52836023   SELECT _ COMMANDS :   26   UPDATE _ COMMANDS :   1   OTHER _ COMMANDS :   145   COMMIT _ TRANSACTIONS :   1   ROLLBACK _ TRANSACTIONS :   0   DENIED _ CONNECTIONS :   0   LOST _ CONNECTIONS :   0   ACCESS _ DENIED :   0   EMPTY _ QUERIES :   0   TOTAL _ SSL _ CONNECTIONS :   0     查询 索引 使用 信息 ： \n mysql & gt ;   SELECT   *   FROM   INFORMATION _ SCHEMA . INDEX _ STATISTICS   WHERE   TABLE _ NAME = ' tables _ priv ' ;   + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - +   |   TABLE _ SCHEMA   |   TABLE _ NAME   |   INDEX _ NAME   |   ROWS _ READ   |   + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - +   |   mysql   |   tables _ priv   |   PRIMARY   |   2   |   + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - +     查询 表 的 使用 信息 ： \n mysql & gt ;   SELECT   *   FROM   INFORMATION _ SCHEMA . TABLE _ STATISTICS   WHERE   TABLE _ NAME = ` ` tables _ priv ` ` ;   + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - +   |   TABLE _ SCHEMA   |   TABLE _ NAME   |   ROWS _ READ   |   ROWS _ CHANGED   |   ROWS _ CHANGED _ X _ INDEXES   |   + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - +   |   mysql   |   tables _ priv   |   2   |   0   |   0   |   + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - + - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - +     具体 详情 详情请 参考 文档 ： https : / / www . percona . com / doc / percona - server / 5.7 / diagnostics / user _ stats . html \n 3 .   check - unused - keys   check - unused - keys   是   Ryan   Lowe   编写 的 基于   userstat   的 一个   perl   脚本 。 能够 比较 方便 输出 需要 删除 的 索引 。 \n 下载 地址 ： https : / / code . google . com / archive / p / check - unused - keys / downloads   /   备份 地址 \n MySQL   设置 ： \n mysql & gt ;   SET   GLOBAL   userstat = ON ;   mysql & gt ;   SET   GLOBAL   ` thread _ statistics ` = 1 ;   mysql & gt ;   SHOW   GLOBAL   VARIABLES   LIKE   & quot ; userstat & quot ; ;   + - - - - - - - - - - - - - - - + - - - - - - - +   |   Variable _ name   |   Value   |   + - - - - - - - - - - - - - - - + - - - - - - - +   |   userstat   |   ON   |   + - - - - - - - - - - - - - - - + - - - - - - - +   1   row   in   set   ( 0.00   sec )     语法 ： \n & gt ;   . / check - unused - keys   - - help     使用 ： \n . / check - unused - keys   - - host = 127.0 . 0.1   - - username = root   - - password = toor   - - port = 3306   - - create - alter     参考 ： \n https : / / www . percona . com / blog / 2009 / 06 / 26 / check - unused - keys - a - tool - to - interact - with - index _ statistics / \n https : / / www . percona . com / blog / 2008 / 09 / 12 / googles - user _ statistics - v2 - port - and - changes / \n https : / / code . google . com / archive / p / check - unused - keys / \n https : / / www . percona . com / blog / 2012 / 12 / 05 / quickly - finding - unused - indexes - and - estimating - their - size / \n https : / / yq . aliyun . com / articles / 308518 \n", "title_s": "mysql   查询 优化 ： 索引 优化"}, {"description": "", "objectID": "https://blog.threeq.me/post/git-branch-flow/", "tags": ["git"], "title": "Git 代码库分之管理", "uri": "https://blog.threeq.me/post/git-branch-flow/", "content": "代码版本库使用git管理，以下是git版本使用规范\n流程图说明 \n分支使用说明    分支名称 名字 说明 实例     master 线上分支 不用于开发，使用tag功能标记版本。只能由beta和hotfix合并，合并同时打上发布版本tag v1.0.2   beta 灰度分支组 灰度分之只能由test合并master产生，在测试通过后进入灰度阶段产生；灰度通过后合并进入master beta/sign   test(release) 测试分支组 只能用于测试和修改bug，只能由由master合并进feature产生。对于测试通过的test，使用merge合并方式合并master产生beta分之；合并后的release需要删除 test/sign; release/active   feature 功能分支组 从最新master检出用于开发一个新功能，一旦完成开发，合并master进入下一个test，删除本次feature分支；负责开发中多开发者代码同步使用 feature/news; feature/vote   topic 本地开发分支组 开发人员基于feature/release/hotfix检出自己本地开发(或修改bug)分支，在开发(或修改bug)中使用rebase合并方式和feature/release/hotfix进行同步。原则上一个feature/release/hotfix分支对应一个topic分支，开发完成的feature/release/hotfix删除对应的topic分支 topic/feature-news-wlp; topic/release-new-wlp; topic/hotfix-news-wlp   hotfix 修补分支组 对于线上紧急bug修改，产生一个hotfix分支，只能由master上的tag标签签出。修改完成的hotfix合并回master，并且必须删除 hotfix/v1.0.2     注意： 1. 个人开发分支除特殊情况，不允许提交到远程服务器中。\n 代码提交/合并说明 这个是开发人在日常开发中使用最多的操作。\n获取代码库 $ git clone &lt;版本库地址&gt; $ cd &lt;代码目录&gt; $ git fetch origin feature/&lt;功能分支&gt;:feature/&lt;功能分支&gt;  建立自己的本地开发分支 $ git checkout feature/&lt;功能分支&gt; $ git checkout -b topic/&lt;功能分支&gt;-&lt;你的标识&gt;  提交修改 $ git status $ git add . $ git commit -am '修改描述'  发布你的修改 $ git fetch origin feature/&lt;功能分支&gt;:feature/&lt;功能分支&gt; $ git rebase feature/&lt;功能分支&gt; # 这里可能会产生合并操作 $ git push origin topic/&lt;功能分支&gt;-&lt;你的标识&gt;:feature/&lt;功能分支&gt;  代码发布说明 发布代码是针对功能发布而定的，发布又分为测试发布和上线发布。对于发布操作，必须是先到测试环境(test)，再从测试环境(test)到灰度环境(beta)，最后从灰度环境(beta)到生产环境(master)，对于线上每次发布都必须有标签记录，可以回退。 原则上从beta到master只会产生 fast-forward 类型操作。以下所有操作都在自己的开发分支中完成。\n发布到测试环境 # 合并feature分支 $ git fetch origin master:master $ git fetch origin feature/&lt;功能分支&gt;:feature/&lt;功能分支&gt; $ git checkout feature/&lt;功能分支&gt; $ git merge master ~~解决冲突~~ # 生产test分支 $ git checkout -b test/&lt;功能分支&gt; $ git push origin test/&lt;功能分支&gt;: test/&lt;功能分支&gt; # 清理feature分支 $ git push origin :feature/&lt;功能分支&gt; $ git branch -D feature/&lt;功能分支&gt;  发布到灰度环境 # 合并master到测试 $ git fetch origin test/&lt;功能分支&gt;:test/&lt;功能分支&gt; $ git fetch origin master:master $ git checkout test/&lt;功能分支&gt; $ git merge master ~~解决冲突~~ # 生成beta分支 $ git checkout -b beta/&lt;功能分支&gt; $ git push origin beta/&lt;功能分支&gt;:beta/&lt;功能名称&gt; # 清理 test $ git push origin :test/&lt;版本&gt; $ git branch -D test/&lt;版本&gt;  发布到生产环境 # 合并到master $ git fetch origin beta/&lt;版本&gt;:beta/&lt;版本&gt; $ git fetch origin master:master $ git checkout master $ git merge beta/&lt;版本&gt; $ git tag -a &lt;发布版本号&gt; -m &quot;发布功能描述&quot; $ git push origin --tags $ git push origin master:master # 清理 beta $ git push origin :beta/&lt;版本&gt; $ git branch -D beta/&lt;版本&gt;  修改生产环境bug # 创建补丁版本，进行修改 $ git fetch origin --tag $ git checkout -b hotfix/&lt;版本号&gt; &lt;版本号&gt; # 修改完成发布 # 1. 合并到master $ git fetch origin master:master $ git checkout master $ git merge hotfix/&lt;版本号&gt; $ git tag -a &lt;发布版本号&gt; -m &quot;发布功能描述&quot; $ git push origin --tag $ git push origin master:master # 清理 hotfix $ git push origin :hotfix/&lt;版本号&gt; $ git branch -D hotfix/&lt;版本号&gt; ", "content_s": "代码 版本 库 使用 git 管理 ， 以下 是 git 版本 使用 规范 \n 流程 流程图 说明   \n 分支 使用 说明         分支 名称   名字   说明   实例           master   线上 分支   不 用于 开发 ， 使用 tag 功能 标记 版本 。 只能 由 beta 和 hotfix 合并 ， 合并 同时 打 上 发布 版本 tag   v1.0 . 2       beta   灰度 分支 组   灰度 分 之 只能 由 test 合并 master 产生 ， 在 测试 通过 测试通过 后 进入 灰度 阶段 产生 ； 灰度 通过 后 合并 进入 master   beta / sign       test ( release )   测试 分支 组   只能 用于 测试 和 修改 bug ， 只能 由 由 master 合并 进 feature 产生 。 对于 测试 通过 测试通过 的 test ， 使用 merge 合并 方式 合并 master 产生 beta 分 之 ； 合并 后 的 release 需要 删除   test / sign ;   release / active       feature   功能 分支 组   从 最新 master 检出 用于 开发 一个 新 功能 ， 一旦 完成 开发 ， 合并 master 进入 下 一个 test ， 删除 本次 feature 分支 ； 负责 开发 中多 开发 开发者 代码 同步 使用   feature / news ;   feature / vote       topic   本地 开发 分支 组   开发 发人 人员 开发人员 基于 feature / release / hotfix 检出 自己 本地 开发 ( 或 修改 bug ) 分支 ， 在 开发 ( 或 修改 bug ) 中 使用 rebase 合并 方式 和 feature / release / hotfix 进行 同步 。 原则 原则上 一个 feature / release / hotfix 分支 对应 一个 topic 分支 ， 开发 完成 的 feature / release / hotfix 删除 对应 的 topic 分支   topic / feature - news - wlp ;   topic / release - new - wlp ;   topic / hotfix - news - wlp       hotfix   修补 分支 组   对于 线上 紧急 bug 修改 ， 产生 一个 hotfix 分支 ， 只能 由 master 上 的 tag 标签 签出 。 修改 完成 的 hotfix 合并 回 master ， 并且 必须 删除   hotfix / v1.0 . 2           注意 ：   1 .   个人 开发 分支 除 特殊 情况 ， 不 允许 提交 到 远程 服务 务器 服务器 中 。 \n   代码 提交 / 合并 说明   这个 是 开发 人 在 日常 开发 中 使用 最多 的 操作 。 \n 获取 代码 库   $   git   clone   & lt ; 版本 库 地址 & gt ;   $   cd   & lt ; 代码 目录 & gt ;   $   git   fetch   origin   feature / & lt ; 功能 分支 & gt ; : feature / & lt ; 功能 分支 & gt ;     建立 自己 的 本地 开发 分支   $   git   checkout   feature / & lt ; 功能 分支 & gt ;   $   git   checkout   - b   topic / & lt ; 功能 分支 & gt ; - & lt ; 你 的 标识 & gt ;     提交 修改   $   git   status   $   git   add   .   $   git   commit   - am   ' 修改 描述 '     发布 你 的 修改   $   git   fetch   origin   feature / & lt ; 功能 分支 & gt ; : feature / & lt ; 功能 分支 & gt ;   $   git   rebase   feature / & lt ; 功能 分支 & gt ;   #   这里 可能 会 产生 合并 操作   $   git   push   origin   topic / & lt ; 功能 分支 & gt ; - & lt ; 你 的 标识 & gt ; : feature / & lt ; 功能 分支 & gt ;     代码 发布 说明   发布 代码 是 针对 功能 发布 而定 的 ， 发布 又 分为 测试 发布 和 上线 发布 。 对于 发布 操作 ， 必须 是 先到 测试 环境 测试环境 ( test ) ， 再 从 测试 环境 测试环境 ( test ) 到 灰度 环境 ( beta ) ， 最后 从 灰度 环境 ( beta ) 到 生产 环境 ( master ) ， 对于 线上 每次 发布 都 必须 有 标签 记录 ， 可以 回退 。   原则 原则上 从 beta 到 master 只会 产生   fast - forward   类型 操作 。 以下 所有 操作 都 在 自己 的 开发 分支 中 完成 。 \n 发布 到 测试 环境 测试环境   #   合并 feature 分支   $   git   fetch   origin   master : master   $   git   fetch   origin   feature / & lt ; 功能 分支 & gt ; : feature / & lt ; 功能 分支 & gt ;   $   git   checkout   feature / & lt ; 功能 分支 & gt ;   $   git   merge   master   ~ ~ 解决 冲突 ~ ~   #   生产 test 分支   $   git   checkout   - b   test / & lt ; 功能 分支 & gt ;   $   git   push   origin   test / & lt ; 功能 分支 & gt ; :   test / & lt ; 功能 分支 & gt ;   #   清理 feature 分支   $   git   push   origin   : feature / & lt ; 功能 分支 & gt ;   $   git   branch   - D   feature / & lt ; 功能 分支 & gt ;     发布 到 灰度 环境   #   合并 master 到 测试   $   git   fetch   origin   test / & lt ; 功能 分支 & gt ; : test / & lt ; 功能 分支 & gt ;   $   git   fetch   origin   master : master   $   git   checkout   test / & lt ; 功能 分支 & gt ;   $   git   merge   master   ~ ~ 解决 冲突 ~ ~   #   生成 beta 分支   $   git   checkout   - b   beta / & lt ; 功能 分支 & gt ;   $   git   push   origin   beta / & lt ; 功能 分支 & gt ; : beta / & lt ; 功能 名称 & gt ;   #   清理   test   $   git   push   origin   : test / & lt ; 版本 & gt ;   $   git   branch   - D   test / & lt ; 版本 & gt ;     发布 到 生产 环境   #   合并 到 master   $   git   fetch   origin   beta / & lt ; 版本 & gt ; : beta / & lt ; 版本 & gt ;   $   git   fetch   origin   master : master   $   git   checkout   master   $   git   merge   beta / & lt ; 版本 & gt ;   $   git   tag   - a   & lt ; 发布 版本 版本号 & gt ;   - m   & quot ; 发布 功能 描述 & quot ;   $   git   push   origin   - - tags   $   git   push   origin   master : master   #   清理   beta   $   git   push   origin   : beta / & lt ; 版本 & gt ;   $   git   branch   - D   beta / & lt ; 版本 & gt ;     修改 生产 环境 bug   #   创建 补丁 版本 ， 进行 修改   $   git   fetch   origin   - - tag   $   git   checkout   - b   hotfix / & lt ; 版本 版本号 & gt ;   & lt ; 版本 版本号 & gt ;   #   修改 完成 发布   #   1 .   合并 到 master   $   git   fetch   origin   master : master   $   git   checkout   master   $   git   merge   hotfix / & lt ; 版本 版本号 & gt ;   $   git   tag   - a   & lt ; 发布 版本 版本号 & gt ;   - m   & quot ; 发布 功能 描述 & quot ;   $   git   push   origin   - - tag   $   git   push   origin   master : master   #   清理   hotfix   $   git   push   origin   : hotfix / & lt ; 版本 版本号 & gt ;   $   git   branch   - D   hotfix / & lt ; 版本 版本号 & gt ;  ", "title_s": "Git   代码 库分 之 管理"}, {"description": "", "objectID": "https://blog.threeq.me/post/%E4%B8%AA%E4%BA%BA%E7%AE%A1%E7%90%86/gtd-flow/", "tags": ["GTD", "时间管理"], "title": "让网络更好为我们服务", "uri": "https://blog.threeq.me/post/%E4%B8%AA%E4%BA%BA%E7%AE%A1%E7%90%86/gtd-flow/", "content": "你每天早上一醒来有没有立即想拿起手机赶紧看一下（facebook、twitter、微信），无论里面有没有信息都要打开一下才安心？并且在上班之前还要想办法挤出时间看一下各大新闻网站，查收邮件在各种邮件信息中找出今天需要处理的事情。并且在工作的时候，一出现一个消息弹框马上点击进去看，害怕自己遗漏哪怕一次消息。\n这些在一个信息爆炸的时代是正常的，被称为信息饥渴。其实出现这个情况是由于我们没有很好获取信息方式和管理信息方法。这篇文章就介绍如何更好的利用网络工具来为我们管理信息。 这里我先把这些网络工具分为：\n 信息产生工具\ngithub、facebook、twitter、rss博客、linkedin、微信服务号  信息收集转换器\nzapier、ifttt、smooch、feedly、pocket、buffer  时间/任务/信息管理工具（GTD）\nEvernote、todoist、kanbanflow、自己博客、bearychat、slack    作为一个有态度的程序员肯定是从我最爱的github开始了，我们在github上面肯定少不了有自己的开源代码，当有人给我们提交一个issue、发起一个pull request等信息时我们\ngithub --&gt; kanbanflow  我把看书作为一项任务来对待，在我看完一本书的时候自动在 Evernote 里面创建一个书评的待完成的笔记，并在 todolist 中建立一个任务放入到待计划中\nkanbanflow --&gt; Evernote --&gt; kanbanflow  对于facebook、twitter等社交工具中有新信息的时候，全部集中到 slack\nfacebook/twitter --&gt; slack  对于各种新闻信息进行快速过滤，对于感兴趣的放入到pocket,同时建立阅读任务；后面在整理pocket的时候需要整理笔记的时候自动在Evernote中建立需要完善的整理笔记和相关todolit任务。\npocket --&gt; todoist pocket --&gt; Evernote --&gt; kanbanflow  对于自己关注的新闻、博客、论坛等信息，订阅rss信息到feedly，如果有信息时自在todolist建立阅读任务；在阅读过程中需要整理笔记的时候自动在Evernote中建立需要完善的整理笔记和相关todolit任务。\nrss/feedly --&gt; kanbanflow rss/feedly --&gt; Evernote --&gt; kanbanflow  对于自己博客更新，会自动同步到twitter、facebook等账户中，并且保存到 Evernote\n自己博客 --&gt; facebook --&gt; twitter --&gt; Evernote  在工作中我们会用到 gitlab、jenkins 等工具，我把这些信息全都收集到 bearychat 中\ngitlab/jenkins --&gt; bearychat  ", "content_s": "你 每天 早上 一 醒来 没有 有没有 立即 想 拿 起 手机 赶紧 看 一下 （ facebook 、 twitter 、 微信 ） ， 无论 里面 没有 有没有 信息 都 要 打开 一下 才 安心 ？ 并且 在 上班 之前 还要 想 办法 挤出 时间 看 一下 各大 新闻 网站 ， 查收 邮件 在 各种 邮件 信息 中 找出 今天 需要 处理 的 事情 。 并且 在 工作 的 时候 ， 一 出现 一个 消息 弹框 马上 点击 进去 看 ， 害怕 自己 遗漏 哪怕 一次 消息 。 \n 这些 在 一个 信息 爆炸 的 时代 是 正常 的 ， 被 称为 信息 饥渴 。 其实 出现 这个 情况 是 由于 我们 没有 很 好 获取 取信 信息 获取信息 方式 和 管理 信息 方法 。 这 文章 篇文章 就 介绍 如何 更好 的 利用 网络 工具 网络工具 来 为 我们 管理 信息 。   这里 我 先 把 这些 网络 工具 网络工具 分为 ： \n   信息 产生 工具 \n github 、 facebook 、 twitter 、 rss 博客 、 linkedin 、 微信 服务 号     信息 收集 转换 转换器 \n zapier 、 ifttt 、 smooch 、 feedly 、 pocket 、 buffer     时间 / 任务 / 信息 管理 信息管理 工具 （ GTD ） \n Evernote 、 todoist 、 kanbanflow 、 自己 博客 、 bearychat 、 slack         作为 一个 有 态度 的 程序 程序员 肯定 是从 我 最 爱 的 github 开始 了 ， 我们 在 github 上面 肯定 不了 少不了 有 自己 的 开 代码 源代码 ， 当 有人 给 我们 提交 一个 issue 、 发起 一个 pull   request 等 信息 时 我们 \n github   - - & gt ;   kanbanflow     我 把 看书 作为 一项 任务 来 对待 ， 在 我 看 完一 本书 的 时候 自动 在   Evernote   里面 创建 一个 书评 的 待 完成 的 笔记 ， 并 在   todolist   中 建立 一个 任务 放入 到 待 计划 中 \n kanbanflow   - - & gt ;   Evernote   - - & gt ;   kanbanflow     对于 facebook 、 twitter 等 社交 工具 中有 新 信息 的 时候 ， 全部 集中 到   slack \n facebook / twitter   - - & gt ;   slack     对于 各种 新闻 信息 进行 快速 过滤 ， 对于 感兴 兴趣 感兴趣 的 放入 到 pocket , 同时 建立 阅读 任务 ； 后面 在 整理 pocket 的 时候 需要 整理 笔记 的 时候 自动 在 Evernote 中 建立 需要 完善 的 整理 笔记 和 相关 todolit 任务 。 \n pocket   - - & gt ;   todoist   pocket   - - & gt ;   Evernote   - - & gt ;   kanbanflow     对于 自己 关注 的 新闻 、 博客 、 论坛 等 信息 ， 订阅 rss 信息 到 feedly ， 如果 有 信息 时自 在 todolist 建立 阅读 任务 ； 在 阅读 过程 中 需要 整理 笔记 的 时候 自动 在 Evernote 中 建立 需要 完善 的 整理 笔记 和 相关 todolit 任务 。 \n rss / feedly   - - & gt ;   kanbanflow   rss / feedly   - - & gt ;   Evernote   - - & gt ;   kanbanflow     对于 自己 博客 更新 ， 会 自动 同步 到 twitter 、 facebook 等 账户 中 ， 并且 保存 到   Evernote \n 自己 博客   - - & gt ;   facebook   - - & gt ;   twitter   - - & gt ;   Evernote     在 工作 中 我们 会 用到   gitlab 、 jenkins   等 工具 ， 我 把 这些 信息 全都 收集 到   bearychat   中 \n gitlab / jenkins   - - & gt ;   bearychat    ", "title_s": "让 网络 更好 为 我们 服务"}, {"description": "", "objectID": "https://blog.threeq.me/post/ci-cd-tool/", "tags": ["jenkins", "gerrit", "gitlab", "redmine", "CI/CD"], "title": "项目持续集成工具", "uri": "https://blog.threeq.me/post/ci-cd-tool/", "content": " 每个项目管理中都有自己的管理工具集合，这里分享一下我用过的工具集合，这里面有些工具的实践时间可能并不是很长时间，列在这里意味这下一个阶段的实践计划。同时也分享一下我自己在选择工具集合的时候考虑的点(关于每类工具如何比较它们最后做出选择我后面会慢慢补上)。在这里不会详细介绍每种工具的安装、连接和使用过程，如果后面有时间我会专门写这些工具的安装、配置和配合使用。 O 首先列出我认为在项目管理中比较重要的工具，同时这些也是我在实践中用得比较多的一套工具集：\n   工具 职责 描述     git  网上有个在线教程很好《pro git》中文版   gerrit 代码库服务器工具/代码审核工具 基于git的在线代码审查工具，围绕它建立代码审核平台和流程   gitlab 版本库展示平台 gitlab这里只作为代码展示平台和最终的发布代码库   jenkins 自动化持续集成平台 jenkins自动测试/集成/发布，围绕它建立可持续集成平台   redmine 任务管理平台/缺陷跟踪平台    sonar 代码质量报告聚合工具 围绕它搭建一个代码质量监控平台    关于上面工具的安装过程不做描述，不过个人建议可以把每个服务都做成docker容器，这样如果需要再次搭建环境就方便了。\n下面对这套工具集合的流程介绍 工具流程 整理流程 {% plantuml %} ACTOR 开发人员 control gerrit control jenkins ACTOR 审核人员 database sonar database gitlab control redmine\n开发人员-&gt;gerrit: 提交代码审核 gerrit-&gt;jenkins: 触发持续集成测试 jenkins-&gt;jenkins: 执行集成测试 jenkins-&gt;sonar: 收集代码质量报告 gerrit&lt;--jenkins: 返回测试结果 gerrit-&gt;审核人员: 通知人工审核 gerrit&lt;--审核人员: 人工审核反馈 gerrit-&gt;gerrit: 验证代码审核结果/代码合并 gerrit-&gt;gitlab: 合并的代码提交到gitlab gitlab-&gt;redmine: 自动更新redmine的缺陷 开发人员&lt;--gerrit: 通知开发人员审核结果  {% endplantuml %}\ngerrit代码审查流程 选择工具的思考 首先要明确一点：不论多么智能的工具，都是为我们程序员服务的，只是为我们提供一个更好工作的环境，让我们可以更愉快的coding。所以在选择一个项目的基础平台环境时，一定要考虑到项目团队的人员情况。\n* 平台工具集可以引导团队成员不断提高自己 * 方便团队任务分配、跟踪 * 团队成员可以随时随地，在自己想看代码的时候方便得到 * 代码质量可视化、可跟踪 * 一切和编码不相关的内容，尽量自动化 * 可持续集成 * 方便文档的编写  同时在项目中哪些方面是需要引入工具的呢？这个答案在每一个团队都会不一样，这里写一些我自己的想法：\n* 代码管理环境 * 任务/缺陷管理环境 * 自动化测试/持续集成环境 * 代码质量监控环境 * 文档编辑环境 * 协作/沟通环境 * 集成开发环境  下面我会对这几方面的工具进行一个简单的考量，说明我自己在这方面的考虑点，但是不会做非常细致的比较，原因有2个： 1. 有很多工具我自己也没有亲身使用过； 2. 每个人或团队对工具的思考都会不同，同时网上有很多的关于它们比拼的文章，最重要的是自己的使用感受和思考\n代码管理环境 代码版本库的管理我相信这个大家都会用工具来管理（如果你还没有使用版本库管理或者还在自己手动管理，我只能呵呵。。。了）。对于不同的版本控制需求，我们需要不同的管理策略，当然这个和团队的协作方式有很大的关系。同时现在的代码版本管理工具也很多：VSS、SVN、GIT、CVS(完全可以用SVN代替)、ClearCase等。那对于代码管理环境需要考虑那些因素： * 安全性(如果你是开源的忠诚粉丝，可以完全忽略这个) * 易用性 * 总体成本 * 技术支持 * 周边产品（衍生工具/其他产品集成工具） * 是否离线操作（这个这里作为考虑条件是因为网络有时确实是一个坑,不解释） * 支持代码审查\n这里我主要比较了git和svn。VSS支持平台有限（感觉只有win）果断干掉（我不好意思让兄弟们把mac换成win吧，呵呵。。。）；ClearCase看到网上介绍感觉功能很强大的，但是看了一下价格果断干掉（原因不要深究。。。）。\nGIT git这个现在很火，用的人很多，包括我自己现在也是完全使用这个。\n 安全性\n 使用这个可以说你的代码都没有什么安全性了(一些专业的git服务器除外)，他对安全性的控制你完全可以忽略。这个也没有办法，谁让他的作者就是开源狂热份子呢 由于他们分布式管理方式，任何一个开发人员本地都有一份完整的代码库克隆，所以任何一个人员或服务器损坏了，也不会对开发有任何影响，同时找回来也是非常方便的，基本不用成本  易用性\n 这个可能就要因人而已了，如果之前对命令行的模式比较熟悉，那这个基本上就没有任何学习曲线了，只是自己的命令集合里面多了一个叫git的命令而已；但是对于之前比较习惯图形界面的童鞋就有学习成本了(实际上从我和兄弟们的使用情况来看，其实不是学习git命令花费时间，而是要让自己习惯命令行工作方式)，不过成本其实是很低的，比如我们团队的兄弟们在一周之内都实用的很溜了(这里给兄弟们赞一个)。 后面就是关于分支的管理、合并、冲突的解决等协作方面的问题，这个从我个人的使用来看问题基本不大，只要把网上的那本《pro git》跟着操作完成，你能需要遇到的问题基本OK了。 最后就是规划团队的代码管理流程了，让代码版本管理在团队不断扩大、项目越来越多的过程中不至于失控 还有一个不经常会用到的操作，就是迁移代码库。这个对于git来说就太容易了，就是2、3个命令的事  总体成本\n 因为是开源的，所以从软件费用来说是0成本 剩下的就是我们自己搭建服务器的成本了，如果感觉自己服务器也不想出，那就找网上的云服务就好了，所以这个成本也是相对叫低的了。这里列举几个我用过的：github、coding.net、Git@OSC具体谁更适合你，都去用一边就好了 最后就是团队的学习成本了，从我在易用性里面介绍，我感觉一个团队学习的成本不会超过1周 同时git的周边产品大多都是免费的或者提供免费版本，所以他的配套产品成本其实很低  技术支持\n 开源的东西就只有社区，这个不要想太多，任何东西都需要你自己去发现，当然如果你选择三方平台，他们会有服务器平台部分支持的  周边产品\n 现在基于git的衍生产品太多了，上面所列举的都是，随便baidu和google都是一大把 其他平台对于git的支持我个人感觉很不错，不论是IDE、持续集成环境、bug跟踪系统都有响应的插件支持git版本库  离线操作\n 这个离线操作也是我之前考虑使用它的一个重要原因，每个人只需要在本地编写好、提交好你的代码，然后找一个网络环境的地方，把代码同步一下就好了   SVN(有这个没有必要CVS了) svn现在用的团队很多，是一种集中式版本管理工具，我之前也是用这个很长一段时间。\n 安全性\n svn的目标就管理团队代码，所以可以很精确的控制每个人远能访问的权限，目录分支等 由于是集中式管理，所以svn服务器千万不能挂掉，如果挂了大家都不能工作了，同时找回代码也是一件费劲的事情  易用性\n svn提供图形化客户端(非linux系统)，所以大家看一下就可以使用了 svn分支、合并、冲突解决都是图形化操作，大家用起来问题不大 大家都习惯了图形操作的方式，所以学习很快 但是在团队不断变大、项目越来越多的时候，对svn的管理就需要有点技巧了  总体成本\n svn软件本身是免费的，所以软件本身费用是0成本 如果自己搭建服务器，那就需要服务器成本了，不过你可以选择网上云服务，如google代码库（国内的就别想了）、svn china、RiouxSVN等。因为我自己以前只使用过google，所以对这些云服务需要自己去体验了 团队学习我们忽略吧 svn的目标毕竟是代替老牌的cvs，周边产品的支持那是杠杠的，其他和软件开发相关的环境和平台，肯定都是支持svn的，如果你选择的基础环境工具中还有不支持svn的，那肯定是你出问题了。但是很多优秀svn的周边产品都是需要收费的  技术支持\n 社区绝对是一个神奇的存在，你遇到的问题，肯定有人解决了，至少我当时是这样的 同时可以买专业的svn产品，这样可以得到专业团队的技术支持，当然这个成本肯定是有的  周边产品\n 刚刚就说了它的目标是代替老牌的cvs，所以周边产品自然不用说，只是成本的问题  离线操作\n 这个是我当时最郁闷的一点，如果你没有网络，你就不能提交了。很不好做历史记录管理   git服务器 这里只介绍git版本库管理中其他的思考。只介绍git是因为我现在使用的git，其实是之前在使用svn的时候没有考虑那么多，自己也没有好好去研究svn的一套体系。\n要使用git作为团队代码管理，就需要git服务器（当然对那些单兵作战的兄弟们，最好也有一个git服务器，这样至少可以做到你在哪里都可以作战）。这里git服务器的选择就有两种方式了：1、使用三方托管平台；2、自己搭建git服务器。这里主要讨论第2种方式，自家搭建服务器。\ngit是基于ssh的，所以如果不要复杂功能只需要一个git-shell就可以是服务器了，不过我们可不想重复找轮子，别人已经弄好的工具，我们为什么不直接用呢！！！Gitosis、 Gitolite（这个东西的权限管理很不错）等。如果要高级功能的(如：web访问)，那gitlab和gerrit（下载需要翻墙）将是不二之选。这里我同时选用了2者，它们的不同在于gerrit是一个更偏向代码审查工具和权限控制。虽然gitlab也可以做代码审查，但是gerrit是做提交前审查，同时对代码权限的控制更细力度；而gitlab是代码提交后审查，同时必须有开发人员手动发起审查，不能自动发起审查操作。这导致他们两个的操作流程有很大区别。我个人更倾向于gerrit的方式，这样可以强迫大家把自己的代码质量提上去，所以我这里选择了两者结合，gerrit这里做权限和质量把控，gitlab做为集成测试和发布版本库。\n任务/缺陷管理环境 缺陷跟踪系统redmine、Bugzilla、BugZero、Trac、jira、trello、bugfree、禅道、coding.net等，现在不论是收费的还是免费的都有很多，我相信任何一个都能解决bug跟踪问题。从我的使用过程中发现这些系统都有各自的有点，同时也有很多不足的地方，最终一个工具是不是符合你们团队，只有试用过才知道。以下是我在使用过程中发现的一些特点，感觉如果从这些点出发去试用和思考一个系统或工具，可以很快判断这个系统或工具是否适合团队，里面有些特性是我使用过的工具里面都没有的，但是这些特点我感觉确实很有用：\n 跨平台客户端（现在大多是web，这个大部分都满足） 可以和其他种类系统集成（如：代码库，测试平台、持续集成环境等） 界面易操作性 多项目管理 自定义流程 当然成本决定算一个 系统更新速度 支持多种开发模式 分级统计功能 移动端支持  持续集成环境 持续集成环境对团队和项目的自动化有一定要求，同时可以也是对团队自动化的一种推进；同时对团队的开发流程和编码风格都会有推动作用。当然至于用什么工具那是其次的，总点是要让团队养成持续集成的习惯和节奏。\n持续集成至应该做到一下几点：\n 自动构建：要求无人值守，如果人工来操作，那就没有持续集成的必要了 发现版本库的变更：通过轮询或者定时，或者程序员使用命令，处罚持续集成发现版本库的变更 反馈机制：在出现问题时，能及时的把问题反馈给正确的人（提交者、测试者、管理者） 回滚：在出现问题后，拥有回滚到可交付的能力 纯净的构建环境：每一次都应该把之前的环境删除干净，让每一次构建都是一个新的构建 完善的集成功能：代码的测试，审查都应该做到完善。如果单纯的利用它做持续的编译，那就是大材小用了 为了避免每次过多出现问题的构建，开发者在提交代码的时候，最好在本地独立的构建一次。可以自行运行构建脚本，模拟构建 由于数据库与编码的分离，最好把数据库相关的DDL\\DML等脚本一起放入版本库中，这样CI进行构建的时候，可以连同数据库一起重新构建 能和我们的代码管理库、任务/缺陷跟踪等其他平台交互  推荐书籍《持续集成：软件质量改进和风险降低之道》\n集成工具：jenkins（前身是Hudson）、gitlab-ci、Apache Continuum、CruiseControl、Luntbuild、drone、shippable\n集成的配置是必不可少的，就是让你定义如何集成构建的构建脚本啦，如果没有一个可配置的构建过程，那持续集成从何说起呢。ant、maven、gradle、make、shell\n由于集成是基于测试之上的，所以一个好的测试工具比不可少，但是这个和团队使用的语言息息相关，每中语言都有自己的测试工具。简单举例已达到抛砖引玉的效果：各种Unit（Junit，HtmlUnit，cppUnit，SQLUnit等）、karma、mocha。。。（手软&gt;_&lt;）\n自动代码审查是提高代码质量，养成代码习惯比可少的，同时这些事情可以自动的做掉，可以让我们更加关注于我们的代码 checkstyle、javaNcss、PMD、siminan、jsHint、jsLint、Emma。。。\n集成反馈和报告这个可以让我们可以实时得到集成结果，失败快速找原因，成功我们就可以安心睡觉了。邮件通知、Jabber、JSCoverage、GCOV、python coverage、JCoverage、Cobertura。。。\n代码质量监控环境 代码质量监控平台其实就是让我们的代码质量可视化、可管理，让我们的代码质量形成历史记录。同时可以非常方便的工全部人员查看。\n 质量可视化 跟踪质量走向（需要历史记录） 可以自动从持续集成环境、代码审查中搜集质量信息 可以和代码管理环境打通，这个的目的是最好能看到每个人代码质量 可以和其他工程管理工具打通  SonarQube、前面介绍的自动代码审查工具\n文档编辑环境 我们的程序员往往都不喜欢写文档，你让他写文档，还不如让他写2倍的代码。但是文档确是我们项目中不可缺少的部分，那怎么让我们的程序员可以高效的写文档呢！其实我们程序员在写文档的时候，往往是被文档的格式所折磨，不能专心的写内容，从而出发对写文档的抵触情绪。所以结合以上我任务文档编写环境应该有一下几点：\n 不用关心格式，重点在内容，格式自动 能从代码中自动生成文档 文档能实时共享、自动共享，像现在用的邮件、QQ之类的其实很影响心情 文档格式足够简单，在写的时候要做到双手不脱离键盘最好  markdown、各种语言doc工具了（jsdoc、javadoc等）、wiki、shpinx\n沟通环境 上面所说的说有东西的最终目的其实都是为了解决我们协作的问题，至少是或多或少都会涉及到协作沟通问题。像现在大家用的最多的沟通工具应该变成QQ、微信之类的了吧，加上邮件、电话、各种协作平台或者其他通讯工具，但是这些工具都有一个特点：在使用的时候都会有一个长时间打断我们思维，或者需要我们专门准备一个时间去做；这些其实都会造成浪费。其实最有效的沟通就是面对面交流，所以构建一个良好的沟通环境，对我们的项目进度起着至关重要的作用：\n 沟通资源随手可得（易于获得），可以在30秒内获得 兄弟们可以采取自己认为高效的方式沟通，同时沟通方式的资源易于获得 沟通历史和结果易于记录，最好能在不察觉的情况下记录起来  项目开发环境 项目开发环境可以分为：工程管理工具和工程开发工具。项目开发环境每个团队都有差别，同时团队内部每个人肯定都有差异，因为它受到的影响因数最多，比如：使用语言，工作内容，个人习惯，操作系统，可能还和心情有关等。因此团队在选择项目开发环境的时候，既要根据团队的定位选定基础开发环境（工程管理工具），同时出一些选择辅助开发环境的选择指导规则；也要考虑每个成员的习惯，开放出来辅助开发环境，让每个成员可以根据自己的习惯，选择一套他自己最高效的项目开发环境集合。下面我列举我认为在选择工程管理工具和工程开发工具应该具备的几点特征：\n工程管理工具  可以和工程开发工具高效集成 可以测试 可以做质量检查 可以和质量管理系统集成  ant，maven，gradle，gulp，grunt，make，cmake。。。\n项目开发工具 项目开发工具也叫做集成开发环境，很多集成开发环境都带有自己的工程管理工具\n 可以和代码管理工具集成 测试必须 可以做本地质量检查 可以方便实现重构手法，关于重构推荐《重构：改变既有代码设计》 最好能和缺陷跟踪系统集成 可以和工程管理工具集成  eclipse、webstorm、vs、idea等\n需求/产品管理环境 对于需求/产品管理环境我自己现在还没有在具体项目中实践过，所以这里就不在阐述了，如果你有好的想法可以给我留言，或者给我连接地址，我连接过去\n测试管理环境 测试管理环境其实应该在持续集成环境里面，但是由于上面写持续集成环境的时候过于偏向开发人员的使用角度介绍了，并且这两套系统确实也是独立存在的。这个测试管理环境更多面向于测试人员，而我认为测试工具本身也是分为测试管理工具和测试执行工具两类别，所以我会从测试管理和测试执行两个方面来说我观点（这里的划分是按照工具的分类划分，并不是按照软件方法的方式划分），同时对于测试我想后面会有专门的一篇文章来介绍，所以这里就这样了，大家见谅我的不专业\n测试管理工具 测试管理我认为比较重要的是：测试计划，测试用例，测试跟踪，缺陷管理(这个和任务/缺陷管理环境一样)\n 可以管理测试计划 可以管理测试用例 可以跟踪每个测试用例的状态 可以和缺陷系统集成 可以和持续集成系统集成  QC(Quality Center)，TestLink，oKit，TD（TestDirector）上面提到的缺陷管理系统\n测试执行工具 测试执行的方式都很多了，并且测试执行种类也很多，比如：自动化测试，性能测试，安全测试，白盒测试等。这里面不同的测试方式所使用的工具都是不一样的：\nselenium，jmeter，jprofile，Wireshark，AppCan，Metasploit，Nmap，Acunetix，Burp Suite，apache ab，Gatling\n还是那句话工具只能给我们提供一个更专心、更快速做事的环境，但是最终这个事情能不能做成、能不能做好完全是取决我们自己。所以不论使用任何工具都行，前提是我们有自己提高的意识和习惯，比如：编码风格、编程习惯、测试习惯、重构习惯、沟通能力、协作能力等，这些才是真真决定项目成败的关键。\n", "content_s": "  每个 项目 管理 项目管理 中 都 有 自己 的 管理 理工 工具 管理工具 集合 ， 这里 分享 一下 我用 过 的 工具 集合 ， 这 里面 有些 工具 的 实践 时间 可能 并 不是 很 时间 长时间 ， 列 在 这里 意味 这下 一个 阶段 的 实践 计划 。 同时 也 分享 一下 我 自己 在 选择 工具 集合 的 时候 考虑 的 点 ( 关于 每 类 工具 如何 比较 它们 最后 做出 选择 我 后面 会 慢慢 补 上 ) 。 在 这里 不会 详细 介绍 每种 工具 的 安装 、 连接 和 使用 过程 ， 如果 后面 有 时间 我会 专门 写 这些 工具 的 安装 、 配置 和 配合 使用 。   O   首先 列出 我 认为 在 项目 管理 项目管理 中 比较 重要 的 工具 ， 同时 这些 也 是 我 实践 在实践中 用 得 比较 多 的 一套 工具 工具集 ： \n       工具   职责   描述           git     网上 有个 在线 教程 在线教程 很 好 《 pro   git 》 中文 文版 中文版       gerrit   代码 库 服务 务器 服务器 工具 / 代码 审核 工具   基于 git 的 在线 代码 审查 工具 ， 围绕 它 建立 代码 审核 平台 和 流程       gitlab   版本 库 展示 平台   gitlab 这里 只 作为 代码 展示 平台 和 最终 的 发布 代码 库       jenkins   自动 自动化 持续 集成 平台   jenkins 自动 测试 自动测试 / 集成 / 发布 ， 围绕 它 建立 可 持续 集成 平台       redmine   任务 管理 平台 / 缺陷 跟踪 平台         sonar   代码 质量 报告 聚合 工具   围绕 它 搭建 一个 代码 质量 监控 平台         关于 上面 工具 的 安装 过程 不 做 描述 ， 不过 个人 建议 可以 把 每个 服务 都 做成 docker 容器 ， 这样 如果 需要 再次 搭建 环境 就 方便 了 。 \n 下面 对 这套 工具 集合 的 流程 介绍   工具 流程   整理 流程   { %   plantuml   % }   ACTOR   开发 发人 人员 开发人员   control   gerrit   control   jenkins   ACTOR   审核 人员   database   sonar   database   gitlab   control   redmine \n 开发 发人 人员 开发人员 - & gt ; gerrit :   提交 代码 审核   gerrit - & gt ; jenkins :   触发 持续 集成 测试   jenkins - & gt ; jenkins :   执行 集成 测试   jenkins - & gt ; sonar :   收集 代码 质量 报告   gerrit & lt ; - - jenkins :   返回 测试 结果   gerrit - & gt ; 审核 人员 :   通知 人工 审核   gerrit & lt ; - - 审核 人员 :   人工 审核 反馈   gerrit - & gt ; gerrit :   验证 代码 审核 结果 / 代码 合并   gerrit - & gt ; gitlab :   合并 的 代码 提交 到 gitlab   gitlab - & gt ; redmine :   自动 更新 自动更新 redmine 的 缺陷   开发 发人 人员 开发人员 & lt ; - - gerrit :   通知 开发 发人 人员 开发人员 审核 结果     { %   endplantuml   % } \n gerrit 代码 审查 流程   选择 工具 的 思考   首先 要 明确 一点 ： 不论 多么 智能 的 工具 ， 都 是 为 我们 程序 程序员 服务 的 ， 只是 为 我们 提供 一个 更好 工作 的 环境 ， 让 我们 可以 更 愉快 的 coding 。 所以 在 选择 一个 项目 的 基础 平台 环境 时 ， 一定 要 考虑 到 项目 团队 的 人员 情况 。 \n *   平台 工具 工具集 可以 引导 团队 成员 不断 提高 自己   *   方便 团队 任务 分配 任务分配 、 跟踪   *   团队 成员 可以 随时 随地 随时随地 ， 在 自己 想 看 代码 的 时候 方便 得到   *   代码 质量 可视 可视化 、 可 跟踪   *   一切 和 编码 不 相关 的 内容 ， 尽量 自动 自动化   *   可 持续 集成   *   方便 文档 的 编写     同时 在 项目 中 哪些 方面 哪些方面 是 需要 引入 工具 的 呢 ？ 这个 答案 在 每 一个 团队 都 会 不 一样 ， 这里 写 一些 我 自己 的 想法 ： \n *   代码 管理 环境   *   任务 / 缺陷 管理 环境   *   自动 自动化 测试 / 持续 集成 环境   *   代码 质量 监控 环境   *   文档 编辑 环境   *   协作 / 沟通 环境   *   集成 开发 环境     下面 我会 对 这 几 方面 的 工具 进行 一个 简单 的 考量 ， 说明 我 自己 在 这方 方面 这方面 的 考虑 点 ， 但是 不会 做 非常 细致 的 比较 ， 原因 有 2 个 ：   1 .   有 很多 工具 我 自己 也 没有 亲身 使用 过 ；   2 .   每个 人 或 团队 对 工具 的 思考 都 会 不同 ， 同时 网上 有 很多 的 关于 它们 比拼 的 文章 ， 最 重要 的 是 自己 的 使用 感受 和 思考 \n 代码 管理 环境   代码 版本 库 的 管理 我 相信 这个 大家 都 会 用 工具 来 管理 （ 如果 你 还 没有 使用 版本 库 管理 或者 还 在 自己 手动 管理 ， 我 只能 呵呵 。 。 。 了 ） 。 对于 不同 的 版本 控制 版本控制 需求 ， 我们 需要 不同 的 管理 策略 管理策略 ， 当然 这个 和 团队 的 协作 方式 有 很大 的 关系 。 同时 现在 的 代码 版本 管理 理工 工具 管理工具 也 很多 ： VSS 、 SVN 、 GIT 、 CVS ( 完全 可以 用 SVN 代替 ) 、 ClearCase 等 。 那 对于 代码 管理 环境 需要 考虑 那些 因素 ：   *   安全 安全性 ( 如果 你 是 开源 的 忠诚 粉丝 ， 可以 完全 忽略 这个 )   *   易用 易用性   *   总体 成本   *   技术 支持 技术支持   *   周边 产品 周边产品 （ 衍生 工具 / 其他 产品 集成 工具 ）   *   是否 离线 操作 （ 这个 这里 作为 考虑 条件 因为 是因为 网络 有时 确实 是 一个 坑 , 不 解释 ）   *   支持 代码 审查 \n 这里 我 主要 比较 了 git 和 svn 。 VSS 支持 平台 有限 （ 感觉 只有 win ） 果断 干掉 （ 我 不好 好意 意思 好意思 不好意思 让 兄弟 们 把 mac 换成 win 吧 ， 呵呵 。 。 。 ） ； ClearCase 看到 网上 介绍 感觉 功能 很 强大 的 ， 但是 看 了 一下 价格 果断 干掉 （ 原因 不要 深究 。 。 。 ） 。 \n GIT   git 这个 现在 很火 ， 用 的 人 很多 ， 包括 我 自己 现在 也 是 完全 使用 这个 。 \n   安全 安全性 \n   使用 这个 可以 说 你 的 代码 都 没有 什么 安全 安全性 了 ( 一些 专业 的 git 服务 务器 服务器 除外 ) ， 他 对 安全 安全性 的 控制 你 完全 可以 忽略 。 这个 也 没有 办法 ， 谁 让 他 的 作者 就是 开源 狂热 份子 呢   由于 他们 分布 布式 分布式 管理 方式 ， 任何 一个 开发 发人 人员 开发人员 本地 都 有 一份 完整 的 代码 库 克隆 ， 所以 任何 一个 人员 或 服务 务器 服务器 损坏 了 ， 也 不会 对 开发 有 任何 影响 ， 同时 找 回来 也 是 非常 方便 的 ， 基本 不用 成本     易用 易用性 \n   这个 可能 就要 因 人 而已 了 ， 如果 之前 对 命令 命令行 的 模式 比较 熟悉 ， 那 这个 基本 基本上 就 没有 任何 学习 曲线 学习曲线 了 ， 只是 自己 的 命令 集合 里面 多 了 一个 叫 git 的 命令 而已 ； 但是 对于 之前 比较 习惯 图形 界面 图形界面 的 童鞋 就 有 学习 成本 了 ( 实际 实际上 从 我 和 兄弟 们 的 使用 情况 来看 ， 其实 不是 学习 git 命令 花费 时间 ， 而是 要 让 自己 习惯 命令 命令行 工作 方式 ) ， 不过 成本 其实 是 很 低 的 ， 比如 我们 团队 的 兄弟 们 在 一周 之内 都 实用 的 很 溜 了 ( 这里 给 兄弟 们 赞 一个 ) 。   后面 就是 关于 分支 的 管理 、 合并 、 冲突 的 解决 等 协作 方面 的 问题 ， 这个 从 我 个人 的 使用 来看 问题 基本 不 大 ， 只要 把 网上 的 那本 《 pro   git 》 跟着 操作 完成 ， 你 能 需要 遇到 的 问题 基本 OK 了 。   最后 就是 规划 团队 的 代码 管理 流程 了 ， 让 代码 版本 管理 在 团队 不断 扩大 不断扩大 、 项目 越来 越来越 多 的 过程 中 至于 不至于 失控   还有 一个 不 经常 会 用到 的 操作 ， 就是 迁移 代码 库 。 这个 对于 git 来说 就 太 容易 了 ， 就是 2 、 3 个 命令 的 事     总体 成本 \n   因为 是 开源 的 ， 所以 从 软件 费用 来说 是 0 成本   剩下 的 就是 我们 自己 搭建 服务 务器 服务器 的 成本 了 ， 如果 感觉 自己 服务 务器 服务器 也 不想 出 ， 那 就 找 网上 的 云 服务 就 好 了 ， 所以 这个 成本 也 是 相对 叫 低 的 了 。 这里 列举 几个 我用 过 的 ： github 、 coding . net 、 Git @ OSC 具体 谁 更 适合 你 ， 都 去 用 一边 就 好 了   最后 就是 团队 的 学习 成本 了 ， 从 我 在 易用 易用性 里面 介绍 ， 我 感觉 一个 团队 学习 的 成本 不会 超过 1 周   同时 git 的 周边 产品 周边产品 大多 都 是 免费 的 或者 提供 免费 版本 ， 所以 他 的 配套 产品 成本 产品成本 其实 很 低     技术 支持 技术支持 \n   开源 的 东西 就 只有 社区 ， 这个 不要 太多 想太多 ， 任何 东西 都 需要 你 自己 去 发现 ， 当然 如果 你 选择 三方 平台 ， 他们 会 有 服务 务器 服务器 平台 部分 支持 的     周边 产品 周边产品 \n   现在 基于 git 的 衍生 产品 太多 了 ， 上面 所 列举 的 都 是 ， 随便 baidu 和 google 都 是 一大 把   其他 平台 对于 git 的 支持 我 个人 感觉 个人感觉 很 不错 ， 不论 不论是 IDE 、 持续 集成 环境 、 bug 跟踪 系统 都 有 响应 的 插件 支持 git 版本 库     离线 操作 \n   这个 离线 操作 也 是 我 之前 考虑 使用 它 的 一个 重要 原因 ， 每个 人 只 需要 在 本地 编写 好 、 提交 好 你 的 代码 ， 然后 找 一个 网络 环境 的 地方 ， 把 代码 同步 一下 就 好 了       SVN ( 有 这个 没有 必要 CVS 了 )   svn 现在 用 的 团队 很多 ， 是 一种 集中 中式 集中式 版本 管理 理工 工具 管理工具 ， 我 之前 也 是 用 这个 很长 一段 时间 段时间 一段时间 。 \n   安全 安全性 \n   svn 的 目标 就 管理 团队 代码 ， 所以 可以 很 精确 的 控制 每个 人远能 访问 的 权限 ， 目录 分支 等   由于 是 集中 中式 集中式 管理 ， 所以 svn 服务 务器 服务器 千万 不能 挂掉 ， 如果 挂 了 大家 都 不能 工作 了 ， 同时 找回 代码 也 是 一件 费劲 的 事情     易用 易用性 \n   svn 提供 图形 图形化 客户 客户端 ( 非 linux 系统 ) ， 所以 大家 看 一下 就 可以 使用 了   svn 分支 、 合并 、 冲突 解决 都 是 图形 图形化 操作 ， 大家 用 起来 问题 不 大   大家 都 习惯 了 图形 操作 图形操作 的 方式 ， 所以 学习 很快   但是 在 团队 不断 变 大 、 项目 越来 越来越 多 的 时候 ， 对 svn 的 管理 就 需要 有点 技巧 了     总体 成本 \n   svn 软件 本身 是 免费 的 ， 所以 软件 本身 费用 是 0 成本   如果 自己 搭建 服务 务器 服务器 ， 那 就 需要 服务 务器 服务器 成本 了 ， 不过 你 可以 选择 网上 云 服务 ， 如 google 代码 库 （ 国内 的 就 别 想 了 ） 、 svn   china 、 RiouxSVN 等 。 因为 我 自己 以前 只 使用 过 google ， 所以 对 这些 云 服务 需要 自己 去 体验 了   团队 学习 我们 忽略 吧   svn 的 目标 毕竟 是 代替 老牌 的 cvs ， 周边 产品 周边产品 的 支持 那 是 杠杠 的 ， 其他 和 软件 开发 软件开发 相关 的 环境 和 平台 ， 肯定 都 是 支持 svn 的 ， 如果 你 选择 的 基础 环境 工具 中 还有 不 支持 svn 的 ， 那 肯定 是 你 出 问题 了 。 但是 很多 优秀 svn 的 周边 产品 周边产品 都 是 需要 收费 的     技术 支持 技术支持 \n   社区 绝对 是 一个 神奇 的 存在 ， 你 遇到 的 问题 ， 肯定 有人 解决 了 ， 至少 我 当时 是 这样 的   同时 可以 买 专业 的 svn 产品 ， 这样 可以 得到 专业 团队 的 技术 支持 技术支持 ， 当然 这个 成本 肯定 是 有 的     周边 产品 周边产品 \n   刚刚 就 说 了 它 的 目标 是 代替 老牌 的 cvs ， 所以 周边 产品 周边产品 自然 不用 不用说 ， 只是 成本 的 问题     离线 操作 \n   这个 是 我 当时 最 郁闷 的 一点 ， 如果 你 没有 网络 ， 你 就 不能 提交 了 。 很 不好 做 历史 史记 记录 历史记录 管理       git 服务 务器 服务器   这里 只 介绍 git 版本 库 管理 中 其他 的 思考 。 只 介绍 git 因为 是因为 我 现在 使用 的 git ， 其实 是 之前 在 使用 svn 的 时候 没有 考虑 那么 多 ， 自己 也 没有 好好 去 研究 svn 的 一套 体系 。 \n 要 使用 git 作为 团队 代码 管理 ， 就 需要 git 服务 务器 服务器 （ 当然 对 那些 单兵 作战 单兵作战 的 兄弟 们 ， 最好 也 有 一个 git 服务 务器 服务器 ， 这样 至少 可以 做到 你 在 哪里 都 可以 作战 ） 。 这里 git 服务 务器 服务器 的 选择 就 有 两种 方式 了 ： 1 、 使用 三方 托管 平台 ； 2 、 自己 搭建 git 服务 务器 服务器 。 这里 主要 讨论 第 2 种 方式 ， 自家 搭建 服务 务器 服务器 。 \n git 是 基于 ssh 的 ， 所以 如果 不要 复杂 功能 只 需要 一个 git - shell 就 可以 是 服务 务器 服务器 了 ， 不过 我们 可 不想 重复 找 轮子 ， 别人 已经 弄 好 的 工具 ， 我们 什么 为什么 不 直接 用 呢 ！ ！ ！ Gitosis 、   Gitolite （ 这个 东西 的 权限 管理 很 不错 ） 等 。 如果 要 高级 功能 的 ( 如 ： web 访问 ) ， 那 gitlab 和 gerrit （ 下载 需要 翻墙 ） 将 是 不二 之选 。 这里 我 同时 选用 了 2 者 ， 它们 的 不同 在于 gerrit 是 一个 更 偏向 代码 审查 工具 和 权限 控制 。 虽然 gitlab 也 可以 做 代码 审查 ， 但是 gerrit 是 做 提交 前 审查 ， 同时 对 代码 权限 的 控制 更细 力度 ； 而 gitlab 是 代码 提交 后 审查 ， 同时 必须 有 开发 发人 人员 开发人员 手动 发起 审查 ， 不能 自动 发起 审查 操作 。 这 导致 他们 两个 的 操作 流程 有 很大 区别 。 我 个人 更 倾向 于 gerrit 的 方式 ， 这样 可以 强迫 大家 把 自己 的 代码 质量 提上 上去 提上去 ， 所以 我 这里 选择 了 两者 结合 ， gerrit 这里 做 权限 和 质量 把 控 ， gitlab 做 为 集成 测试 和 发布 版本 库 。 \n 任务 / 缺陷 管理 环境   缺陷 跟踪 系统 redmine 、 Bugzilla 、 BugZero 、 Trac 、 jira 、 trello 、 bugfree 、 禅道 、 coding . net 等 ， 现在 不论 不论是 收费 的 还是 免费 的 都 有 很多 ， 我 相信 任何 一个 都 能 解决 bug 跟踪 问题 。 从 我 的 使用 过程 中 发现 这些 系统 都 有 各自 的 有点 ， 同时 也 有 很多 不足 的 地方 ， 最终 一个 工具 不是 是不是 符合 你们 团队 ， 只有 试用 过才 知道 。 以下 是 我 在 使用 过程 中 发现 的 一些 特点 ， 感觉 如果 从 这些 点 出发 去 试用 和 思考 一个 系统 或 工具 ， 可以 很快 判断 这个 系统 或 工具 是否 适合 团队 ， 里面 有些 特性 是 我 使用 过 的 工具 里面 都 没有 的 ， 但是 这些 特点 我 感觉 确实 很 有用 ： \n   平台 跨平台 客户 客户端 （ 现在 大多 是 web ， 这个 大部 部分 大部分 都 满足 ）   可以 和 其他 种类 系统 集成 系统集成 （ 如 ： 代码 库 ， 测试 平台 、 持续 集成 环境 等 ）   界面 易 操作 操作性   多 项目 管理 项目管理   自定 定义 自定义 流程   当然 成本 决定 算 一个   系统 更新 速度   支持 多种 开发 模式   分级 统计 功能   移动 端 支持     持续 集成 环境   持续 集成 环境 对 团队 和 项目 的 自动 自动化 有 一定 要求 ， 同时 可以 也 是 对 团队 自动 自动化 的 一种 推进 ； 同时 对 团队 的 开发 流程 和 编码 风格 都 会 有 推动 作用 。 当然 至于 用 什么 工具 那 是 其次 的 ， 总点 是 要 让 团队 养成 持续 集成 的 习惯 和 节奏 。 \n 持续 集成 至 应该 做到 一下 几点 ： \n   自动 构建 ： 要求 无人 值守 ， 如果 人工 来 操作 ， 那 就 没有 持续 集成 的 必要 了   发现 版本 库 的 变更 ： 通过 轮询 或者 定时 ， 或者 程序 程序员 使用 命令 ， 处罚 持续 集成 发现 版本 库 的 变更   反馈 机制 ： 在 出现 问题 时 ， 能 及时 的 把 问题 反馈 给 正确 的 人 （ 提交 提交者 、 测试 测试者 、 管理 管理者 ）   回滚 ： 在 出现 问题 后 ， 拥有 回滚 到 可 交付 的 能力   纯净 的 构建 环境 ： 每 一次 都 应该 把 之前 的 环境 删除 干净 ， 让 每 一次 构建 都 是 一个 新 的 构建   完善 的 集成 功能 ： 代码 的 测试 ， 审查 都 应该 做到 完善 。 如果 单纯 的 利用 它 做 持续 的 编译 ， 那 就是 大材小用 了   为了 避免 每次 过多 出现 问题 的 构建 ， 开发 开发者 在 提交 代码 的 时候 ， 最好 在 本地 独立 的 构建 一次 。 可以 自行 运行 构建 脚本 ， 模拟 构建   由于 数据 据库 数据库 与 编码 的 分离 ， 最好 把 数据 据库 数据库 相关 的 DDL \\ DML 等 脚本 一起 放入 版本 库中 ， 这样 CI 进行 构建 的 时候 ， 可以 连同 数据 据库 数据库 一起 重新 构建   能 和 我们 的 代码 管理 库 、 任务 / 缺陷 跟踪 等 其他 平台 交互     推荐 书籍 《 持续 集成 ： 软件 质量 改进 和 风险 降低 之道 》 \n 集成 工具 ： jenkins （ 前身 是 Hudson ） 、 gitlab - ci 、 Apache   Continuum 、 CruiseControl 、 Luntbuild 、 drone 、 shippable \n 集成 的 配置 是 不可 必不可少 的 ， 就是 让 你 定义 如何 集成 构建 的 构建 脚本 啦 ， 如果 没有 一个 可 配置 的 构建 过程 ， 那 持续 集成 说起 从何说起 呢 。 ant 、 maven 、 gradle 、 make 、 shell \n 由于 集成 是 基于 测试 之上 的 ， 所以 一个 好 的 测试 试工 工具 测试工具 比 不可 少 ， 但是 这个 和 团队 使用 的 语言 相关 息息相关 ， 每中 语言 都 有 自己 的 测试 试工 工具 测试工具 。 简单 举例 已 达到 抛砖 抛砖引玉 的 效果 ： 各种 Unit （ Junit ， HtmlUnit ， cppUnit ， SQLUnit 等 ） 、 karma 、 mocha 。 。 。 （ 手软 & gt ; _& lt ; ） \n 自动 代码 审查 是 提高 代码 质量 ， 养成 代码 习惯 比可少 的 ， 同时 这些 事情 可以 自动 的 做 掉 ， 可以 让 我们 更加 关注 于 我们 的 代码   checkstyle 、 javaNcss 、 PMD 、 siminan 、 jsHint 、 jsLint 、 Emma 。 。 。 \n 集成 反馈 和 报告 这个 可以 让 我们 可以 实时 得到 集成 结果 ， 失败 快速 找 原因 ， 成功 我们 就 可以 安心 睡觉 了 。 邮件 通知 、 Jabber 、 JSCoverage 、 GCOV 、 python   coverage 、 JCoverage 、 Cobertura 。 。 。 \n 代码 质量 监控 环境   代码 质量 监控 平台 其实 就是 让 我们 的 代码 质量 可视 可视化 、 可 管理 ， 让 我们 的 代码 质量 形成 历史 史记 记录 历史记录 。 同时 可以 非常 方便 的 工 全部 人员 查看 。 \n   质量 可视 可视化   跟踪 质量 走向 （ 需要 历史 史记 记录 历史记录 ）   可以 自动 从 持续 集成 环境 、 代码 审查 中 搜集 质量 信息   可以 和 代码 管理 环境 打通 ， 这个 的 目的 是 最好 能 看到 每个 人 代码 质量   可以 和 其他 工程 管理 理工 工具 管理工具 打通     SonarQube 、 前面 介绍 的 自动 代码 审查 工具 \n 文档 编辑 环境   我们 的 程序 程序员 往往 都 不 喜欢 写 文档 ， 你 让 他 写 文档 ， 还 不如 让 他 写 2 倍 的 代码 。 但是 文档 确是 我们 项目 中 不可 缺少 的 部分 ， 那 怎么 让 我们 的 程序 程序员 可以 高效 的 写 文档 呢 ！ 其实 我们 程序 程序员 在 写 文档 的 时候 ， 往往 是 被 文档 的 格式 所 折磨 ， 不能 专心 的 写 内容 ， 从而 出发 对 写 文档 的 抵触 情绪 抵触情绪 。 所以 结合 以上 我 任务 文档 编写 环境 应该 有 一下 几点 ： \n   不用 关心 格式 ， 重点 在 内容 ， 格式 自动   能 从 代码 中 自动 生成 文档   文档 能 实时 共享 、 自动 共享 ， 像 现在 用 的 邮件 、 QQ 之类 的 其实 很 影响 心情   文档 格式 足够 简单 ， 在 写 的 时候 要 做到 双手 不 脱离 键盘 最好     markdown 、 各种 语言 doc 工具 了 （ jsdoc 、 javadoc 等 ） 、 wiki 、 shpinx \n 沟通 环境   上面 所说 的 说 有 东西 的 最终 目的 其实 都 是 为了 解决 我们 协作 的 问题 ， 至少 是 或多或少 都 会 涉及 到 协作 沟通 问题 。 像 现在 大家 用 的 最 多 的 沟通 工具 应该 变成 QQ 、 微信 之类 的 了 吧 ， 加上 邮件 、 电话 、 各种 协作 平台 或者 其他 通讯 工具 ， 但是 这些 工具 都 有 一个 特点 ： 在 使用 的 时候 都 会 有 一个 时间 长时间 打断 我们 思维 ， 或者 需要 我们 专门 准备 一个 时间 去 做 ； 这些 其实 都 会 造成 浪费 。 其实 最 有效 的 沟通 就是 面对 对面 面对面 交流 ， 所以 构建 一个 良好 的 沟通 环境 ， 对 我们 的 项目 进度 起着 至关 重要 至关重要 的 作用 ： \n   沟通 资源 随手 可 得 （ 易于 获得 ） ， 可以 在 30 秒 内 获得   兄弟 们 可以 采取 自己 认为 高效 的 方式 沟通 ， 同时 沟通 方式 的 资源 易于 获得   沟通 历史 和 结果 易于 记录 ， 最好 能 在 不 察觉 的 情况 下 记录 起来     项目 开发 环境   项目 开发 环境 可以 分为 ： 工程 管理 理工 工具 管理工具 和 工程 开发 工具 开发工具 。 项目 开发 环境 每个 团队 都 有 差别 ， 同时 团队 内部 每个 人 肯定 都 有 差异 ， 因为 它 受到 的 影响 因 最多 数最多 ， 比如 ： 使用 语言 ， 工作 内容 ， 个人 习惯 ， 操作 系统 操作系统 ， 可能 还 和 心情 有关 等 。 因此 团队 在 选择 项目 开发 环境 的 时候 ， 既 要 根据 团队 的 定位 选定 基础 开发 环境 （ 工程 管理 理工 工具 管理工具 ） ， 同时 出 一些 选择 辅助 开发 环境 的 选择 指导 规则 ； 也 要 考虑 每个 成员 的 习惯 ， 开放 出来 辅助 开发 环境 ， 让 每个 成员 可以 根据 自己 的 习惯 ， 选择 一套 他 自己 最 高效 的 项目 开发 环境 集合 。 下面 我 列举 我 认为 在 选择 工程 管理 理工 工具 管理工具 和 工程 开发 工具 开发工具 应该 具备 的 几点 特征 ： \n 工程 管理 理工 工具 管理工具     可以 和 工程 开发 工具 开发工具 高效 集成   可以 测试   可以 做 质量 检查 质量检查   可以 和 质量 管理 系统 管理系 管理系统 集成     ant ， maven ， gradle ， gulp ， grunt ， make ， cmake 。 。 。 \n 项目 开发 工具 开发工具   项目 开发 工具 开发工具 也 叫做 集成 开发 环境 ， 很多 集成 开发 环境 都 带有 自己 的 工程 管理 理工 工具 管理工具 \n   可以 和 代码 管理 理工 工具 管理工具 集成   测试 必须   可以 做 本地 质量 检查 质量检查   可以 方便 实现 重构 手法 ， 关于 重构 推荐 《 重构 ： 改变 既有 代码 设计 》   最好 能 和 缺陷 跟踪 系统 集成 系统集成   可以 和 工程 管理 理工 工具 管理工具 集成     eclipse 、 webstorm 、 vs 、 idea 等 \n 需求 / 产品 管理 环境   对于 需求 / 产品 管理 环境 我 自己 现在 还 没有 在 具体 项目 中 实践 过 ， 所以 这里 就 不 在 阐述 了 ， 如果 你 有 好 的 想法 可以 给 我 留言 ， 或者 给 我 连接 地址 ， 我 连接 过去 \n 测试 管理 环境   测试 管理 环境 其实 应该 在 持续 集成 环境 里面 ， 但是 由于 上面 写 持续 集成 环境 的 时候 过于 偏向 开发 发人 人员 开发人员 的 使用 角度 介绍 了 ， 并且 这 两套 系统 确实 也 是 独立 存在 的 。 这个 测试 管理 环境 更 多 面向 于 测试 人员 测试人员 ， 而 我 认为 测试 试工 工具 测试工具 本身 也 是 分为 测试 管理 理工 工具 管理工具 和 测试 执行 工具 两 类别 ， 所以 我会 从 测试 管理 和 测试 执行 两个 方面 来说 我 观点 （ 这里 的 划分 是 按照 工具 的 分类 划分 ， 并 不是 按照 软件 方法 的 方式 划分 ） ， 同时 对于 测试 我 想 后面 会 有 专门 的 一篇 文章 来 介绍 ， 所以 这里 就 这样 了 ， 大家 见谅 我 的 不 专业 \n 测试 管理 理工 工具 管理工具   测试 管理 我 认为 比较 重要 的 是 ： 测试 计划 测试计划 ， 测试 试用 测试用例 ， 测试 跟踪 ， 缺陷 管理 ( 这个 和 任务 / 缺陷 管理 环境 一样 ) \n   可以 管理 测试 计划 测试计划   可以 管理 测试 试用 测试用例   可以 跟踪 每个 测试 试用 测试用例 的 状态   可以 和 缺陷 系统 集成 系统集成   可以 和 持续 集成 系统 集成 系统集成     QC ( Quality   Center ) ， TestLink ， oKit ， TD （ TestDirector ） 上面 提到 的 缺陷 管理 系统 管理系 管理系统 \n 测试 执行 工具   测试 执行 的 方式 都 很多 了 ， 并且 测试 执行 种类 也 很多 ， 比如 ： 自动 自动化 测试 ， 性能 测试 ， 安全 测试 ， 白盒 测试 等 。 这 里面 不同 的 测试 方式 所 使用 的 工具 都 是 不 一样 的 ： \n selenium ， jmeter ， jprofile ， Wireshark ， AppCan ， Metasploit ， Nmap ， Acunetix ， Burp   Suite ， apache   ab ， Gatling \n 还是 那句话 工具 只能 给 我们 提供 一个 更 专心 、 更 快速 做事 的 环境 ， 但是 最终 这个 事情 能 不能 做成 、 能 不能 做好 完全 是 取决 我们 自己 。 所以 不论 使用 任何 工具 都行 ， 前提 是 我们 有 自己 提高 的 意识 和 习惯 ， 比如 ： 编码 风格 、 编程 习惯 、 测试 习惯 、 重构 习惯 、 沟通 能力 、 协作 能力 等 ， 这些 才 是 真真 决定 项目 成败 的 关键 。 \n", "title_s": "项目 持续 集成 工具"}, {"description": "", "objectID": "https://blog.threeq.me/post/web/css3-added-selector/", "tags": ["css3"], "title": "CSS3 新增选择器", "uri": "https://blog.threeq.me/post/web/css3-added-selector/", "content": "现代前端开发中css3已经是不可其他的一部分，早已成为每个web开发人员必备技能之一。 而选择器又是css中最基础、最重要的知识点，对于我们页面结构和代码接口都有着举足轻重的作用。 今天我们就来看看css3所支持的和新增的选择器。\n\n1. CSS1定义的选择器    选择器 类型 说明     E 类型选择器 选择指定类型的元素   E#id ID选择器 选择匹配E的元素，且匹配元素的id为“id”，E选择符可以省略。   E.class 类选择器 选择匹配E的元素，且匹配元素的class属性值为“class”，E选择符可以省略。   E F 包含选择器 选择匹配F的元素，且该元素被包含在匹配E的元素内。   E:link 链接伪类选择器 选择匹配E的元素，且匹配元素被定义了超链接并未被访问。例：a:link、#a_id:link   E:visited 链接伪类选择器 选择匹配E的元素，且匹配元素被定义了超链接并已被访问。例：a:visited   E:active 用户操作伪类选择器 选择匹配E的元素，且匹配元素被激活   E:hover 用户操作伪类选择器 选择匹配E的元素，且匹配元素正被鼠标经过   E:focus 用户操作伪类选择器 选择匹配E的元素，且匹配元素获取了焦点   E:first-line 伪元素选择器 选择匹配E元素内的第一行文本   E:first-letter 伪元素选择器 选择匹配E元素内的第一个字符    2. CSS2定义的选择器    选择器 类型 说明     * 通配选择器 选择文档中所有元素   E[foo] 属性选择器 选择匹配E的元素，且该元素定义了foo属性。E选择符可以省略，表示选择定义了foo属性的任意类型的元素。   E[foo=&ldquo;bar&rdquo;] 属性选择器 选择匹配E的元素，且该元素foo属性值为“bar”   E[foo~=&ldquo;bar&rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值是一个以空格符分隔的列表，其中一个列表的值为“bar”，E选择符可以省略。   E[foo!=&ldquo;en&rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值是一个用连字符（-）分隔的列表，值以“en”开头。   E:first-child 结构伪类选择器 选择匹配E的元素，且该元素为父元素的第一个子元素   E:before 伪元素选择器 在匹配E的元素前面插入内容   E:after 伪元素选择器 在匹配E的元素后面插入内容   E &gt; F 子包含选择器 选择匹配F的元素，且该元素为所匹配E元素的子元素。   E + F 相邻兄弟选择器 选择匹配F的元素，且该元素为所匹配E元素后面相邻的位置。   E:lang(language) 语言选择器 例如：p:lang(it) 选择带有以 &ldquo;it&rdquo; 开头的 lang 属性值的每个  元素。    3. CSS3新增属性选择器    选择器 类型 说明     E[foo^=&ldquo;bar&rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值以“bar”开始。E选择符可以省略，表示可匹配任意类型的元素。   E[foo$=&ldquo;bar&rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值以“bar”结束。E选择符可以省略，表示可匹配任意类型的元素。   E[foo*=&ldquo;bar&rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值包含“bar”。E选择符可以省略，表示可匹配任意类型的元素。   E:root 结构伪类选择器 选择匹配E所在文档的根元素。在（X）HTML文档中，根元素就是html元素，此时该选择器与html类型选择器匹配的内容相同。   E:nth-child(n) 结构伪类选择器 选择所有在其父元素中第n个位置的匹配E的子元素。\n注意，参数n可以是数字（1、2、3）、关键字（odd、even）、公式（2n、2n+3）参数的索引从1开始。\ntr:nth-child(3)匹配所有表格中第3排的tr；\ntr:nth-child(2n+1)匹配所有表格的奇数行；\ntr:nth-child(2n)匹配所有表格的偶数行；\ntr:nth-child(odd)匹配所有表格的奇数行；\ntr:nth-child(even)匹配所有表格的偶数行；   E:nth-last-child(n) 结构伪类选择器 选择所有在其父元素中倒数第n个位置的匹配E的子元素   E:nth-of-type(n) 结构伪类选择器 选择父元素中第n个位置，且匹配E的子元素。\n注意，所有匹配E的子元素被分离出来单独排序。非E的子元素不参与排序。参数n可以是数字，关键字、公式。\n例：p:nth-of-type(1)   E:nth-last-of-type(n) 结构伪类选择器 选择父元素中倒数第n个位置，且匹配E的子元素。   E:last-child 结构伪类选择器 选择位于其父元素中最后一个位置，且匹配E的子元素。   E:first-of-type 结构伪类选择器 选择位于其父元素中且匹配E的第一个同类型的子元素。\n该选择器的功能类似于 E:nth-of-type(1)   E:last-of-type 结构伪类选择器 选择位于其父元素中且匹配E的最后第一个同类型的子元素。\n该选择器的功能类似于 E:nth-last-of-type(1)   E:only-child 结构伪类选择器 选择其父元素只包含一个子元素，且该子元素匹配E。   E:only-of-type 结构伪类选择器 选择其父元素只包含一个同类型的子元素，且该子元素匹配E。   E:empty 结构伪类选择器 选择匹配E的元素，且该元素不包含子节点   E:enabled UI状态伪类选择器 选择匹配E的所有可用UI元素。   E:disabled UI状态伪类选择器 选择匹配E的所有不可用UI元素。   E:checked UI状态伪类选择器 选择匹配E的所有可用UI元素。\n例：input:checked匹配input type为radio及checkbox元素   ::selection UI状态伪类选择器 选择被用户选取的元素部分。   E ~ F 相邻兄弟选择器 选择匹配F的所有元素，且匹配元素位于匹配E的元素后面。在DOM结构树中，E和F所匹配的元素应该在同一级结构上。   E:not(s) 否定伪类选择器 选择匹配E的所有元素，且过滤掉匹配s选择符的任意元素。s是一个简单结构的选择器，不能使用符合选择器，   E:target 目标伪类选择器 选择匹配E的所有元素，且匹配元素被相关URL指向。\n注意：该选择器是动态选择器，只有存在URL指向该匹配元素时，样式才起效果。\n例：demo.html#id    参考：http://www.w3school.com.cn/cssref/css_selectors.asp\n", "content_s": "现代 前端 开发 前端开发 中 css3 已经 是 不可 其他 的 一部 部分 一部分 ， 早已 成为 每个 web 开发 发人 人员 开发人员 必备 技能 之一 。   而 选择 选择器 又 是 css 中 最 基础 、 最 重要 的 知识 知识点 ， 对于 我们 页面 结构 和 代码 接口 都 有着 举足 足轻 轻重 举足轻重 的 作用 。   今天 我们 就 来 看看 css3 所 支持 的 和 新增 的 选择 选择器 。 \n \n 1 .   CSS1 定义 的 选择 选择器         选择 选择器   类型   说明           E   类型 选择 选择器   选择 指定 类型 的 元素       E # id   ID 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 的 id 为 “ id ” ， E 选择 选择符 可以 省略 。       E . class   类 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 的 class 属性 值为 “ class ” ， E 选择 选择符 可以 省略 。       E   F   包含 选择 选择器   选择 匹配 F 的 元素 ， 且 该 元素 被 包含 在 匹配 E 的 元素 内 。       E : link   链接 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 被 定义 了 链接 超链接 并未 被 访问 。 例 ： a : link 、 # a _ id : link       E : visited   链接 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 被 定义 了 链接 超链接 并 已 被 访问 。 例 ： a : visited       E : active   用户 操作 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 被 激活       E : hover   用户 操作 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 正 被 鼠标 经过       E : focus   用户 操作 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 匹配 元素 获取 了 焦点       E : first - line   伪 元素 选择 选择器   选择 匹配 E 元素 内 的 第一 一行 第一行 文本       E : first - letter   伪 元素 选择 选择器   选择 匹配 E 元素 内 的 第一 一个 第一个 字符         2 .   CSS2 定义 的 选择 选择器         选择 选择器   类型   说明           *   通配 选择 选择器   选择 文档 中 所有 元素       E [ foo ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 定义 了 foo 属性 。 E 选择 选择符 可以 省略 ， 表示 选择 定义 了 foo 属性 的 任意 类型 的 元素 。       E [ foo = & ldquo ; bar & rdquo ; ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 foo 属性 值为 “ bar ”       E [ foo ~ = & ldquo ; bar & rdquo ; ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 定义 了 foo 属性 ， foo 属性 值 是 一个 以 空格 空格符 分隔 的 列表 ， 其中 一个 列表 的 值 为 “ bar ” ， E 选择 选择符 可以 省略 。       E [ foo ! = & ldquo ; en & rdquo ; ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 定义 了 foo 属性 ， foo 属性 值 是 一个 用 连 字符 （ - ） 分隔 的 列表 ， 值以 “ en ” 开头 。       E : first - child   结构 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 为父 元素 的 第一 一个 第一个 子 元素       E : before   伪 元素 选择 选择器   在 匹配 E 的 元素 前面 插入 内容       E : after   伪 元素 选择 选择器   在 匹配 E 的 元素 后面 插入 内容       E   & gt ;   F   子 包含 选择 选择器   选择 匹配 F 的 元素 ， 且 该 元素 为 所 匹配 E 元素 的 子 元素 。       E   +   F   相邻 兄弟 选择 选择器   选择 匹配 F 的 元素 ， 且 该 元素 为 所 匹配 E 元素 后面 相邻 的 位置 。       E : lang ( language )   语言 选择 选择器   例如 ： p : lang ( it )   选择 带有 以   & ldquo ; it & rdquo ;   开头 的   lang   属性 值 的 每个     元素 。         3 .   CSS3 新增 属性 选择 选择器         选择 选择器   类型   说明           E [ foo ^ = & ldquo ; bar & rdquo ; ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 定义 了 foo 属性 ， foo 属性 值以 “ bar ” 开始 。 E 选择 选择符 可以 省略 ， 表示 可 匹配 任意 类型 的 元素 。       E [ foo $ = & ldquo ; bar & rdquo ; ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 定义 了 foo 属性 ， foo 属性 值以 “ bar ” 结束 。 E 选择 选择符 可以 省略 ， 表示 可 匹配 任意 类型 的 元素 。       E [ foo * = & ldquo ; bar & rdquo ; ]   属性 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 定义 了 foo 属性 ， foo 属性 值 包含 “ bar ” 。 E 选择 选择符 可以 省略 ， 表示 可 匹配 任意 类型 的 元素 。       E : root   结构 伪类 选择 选择器   选择 匹配 E 所在 文档 的 根 元素 。 在 （ X ） HTML 文档 中 ， 根 元素 就是 html 元素 ， 此时 该 选择 选择器 与 html 类型 选择 选择器 匹配 的 内容 相同 。       E : nth - child ( n )   结构 伪类 选择 选择器   选择 所有 在 其父 元素 中 第 n 个 位置 的 匹配 E 的 子 元素 。 \n 注意 ， 参数 n 可以 是 数字 （ 1 、 2 、 3 ） 、 关键 关键字 （ odd 、 even ） 、 公式 （ 2n 、 2n + 3 ） 参数 的 索引 从 1 开始 。 \n tr : nth - child ( 3 ) 匹配 所有 表格 中 第 3 排 的 tr ； \n tr : nth - child ( 2n + 1 ) 匹配 所有 表格 的 奇数 行 ； \n tr : nth - child ( 2n ) 匹配 所有 表格 的 偶数 行 ； \n tr : nth - child ( odd ) 匹配 所有 表格 的 奇数 行 ； \n tr : nth - child ( even ) 匹配 所有 表格 的 偶数 行 ；       E : nth - last - child ( n )   结构 伪类 选择 选择器   选择 所有 在 其父 元素 中 倒数 倒数第 n 个 位置 的 匹配 E 的 子 元素       E : nth - of - type ( n )   结构 伪类 选择 选择器   选择 父 元素 中 第 n 个 位置 ， 且 匹配 E 的 子 元素 。 \n 注意 ， 所有 匹配 E 的 子 元素 被 分离 出来 分离出来 单独 排序 。 非 E 的 子 元素 不 参与 排序 。 参数 n 可以 是 数字 ， 关键 关键字 、 公式 。 \n 例 ： p : nth - of - type ( 1 )       E : nth - last - of - type ( n )   结构 伪类 选择 选择器   选择 父 元素 中 倒数 倒数第 n 个 位置 ， 且 匹配 E 的 子 元素 。       E : last - child   结构 伪类 选择 选择器   选择 位于 其父 元素 中 最后 一个 位置 ， 且 匹配 E 的 子 元素 。       E : first - of - type   结构 伪类 选择 选择器   选择 位于 其父 元素 中且 匹配 E 的 第一 一个 第一个 同 类型 的 子 元素 。 \n 该 选择 选择器 的 功能 类似 于   E : nth - of - type ( 1 )       E : last - of - type   结构 伪类 选择 选择器   选择 位于 其父 元素 中且 匹配 E 的 最后 第一 一个 第一个 同 类型 的 子 元素 。 \n 该 选择 选择器 的 功能 类似 于   E : nth - last - of - type ( 1 )       E : only - child   结构 伪类 选择 选择器   选择 其父 元素 只 包含 一个 子 元素 ， 且 该子 元素 匹配 E 。       E : only - of - type   结构 伪类 选择 选择器   选择 其父 元素 只 包含 一个 同 类型 的 子 元素 ， 且 该子 元素 匹配 E 。       E : empty   结构 伪类 选择 选择器   选择 匹配 E 的 元素 ， 且 该 元素 不 包含 子 节点       E : enabled   UI 状态 伪类 选择 选择器   选择 匹配 E 的 所有 可用 UI 元素 。       E : disabled   UI 状态 伪类 选择 选择器   选择 匹配 E 的 所有 不可 用 UI 元素 。       E : checked   UI 状态 伪类 选择 选择器   选择 匹配 E 的 所有 可用 UI 元素 。 \n 例 ： input : checked 匹配 input   type 为 radio 及 checkbox 元素       : : selection   UI 状态 伪类 选择 选择器   选择 被 用户 选取 的 元素 部分 。       E   ~   F   相邻 兄弟 选择 选择器   选择 匹配 F 的 所有 元素 ， 且 匹配 元素 位于 匹配 E 的 元素 后面 。 在 DOM 结构 树中 ， E 和 F 所 匹配 的 元素 应该 在 同 一级 结构 上 。       E : not ( s )   否定 伪类 选择 选择器   选择 匹配 E 的 所有 元素 ， 且 过滤 掉 匹配 s 选择 选择符 的 任意 元素 。 s 是 一个 简单 结构 的 选择 选择器 ， 不能 使用 符合 选择 选择器 ，       E : target   目标 伪类 选择 选择器   选择 匹配 E 的 所有 元素 ， 且 匹配 元素 被 相关 URL 指向 。 \n 注意 ： 该 选择 选择器 是 动态 选择 选择器 ， 只有 存在 URL 指向 该 匹配 元素 时 ， 样式 才 起 效果 。 \n 例 ： demo . html # id         参考 ： http : / / www . w3school . com . cn / cssref / css _ selectors . asp \n", "title_s": "CSS3   新增 选择 选择器"}, {"description": "Threeq - 出井的青蛙介绍", "objectID": "https://blog.threeq.me/about/", "tags": [], "title": "关于 Threeq - 出井的青蛙", "uri": "https://blog.threeq.me/about/", "content": " Threeq - 出井的青蛙  快乐的程序员、老司机。\n喜欢专研、思考和专研遇到的难题，不论是技术上还是团队管理上。\n对新技术保持好奇、热爱和谨慎的态度。坚信技术能让明天更美好。\n喜欢分享，开源追随者，崇尚敏捷开发实践。\n常用语言 Java、Python、Golang、Javascript\n目前正在实践 Scrum + 看板 + 领域驱动设计（DDD） + 微服务\n目前正在学 习机器学习（ML）、分布式系统架构设计、k8s 技术栈\n欢迎一起交流学习（非诚勿扰）   扫码联系我   ", "content_s": "  Threeq   -   出井 的 青蛙     快乐 的 程序 程序员 、 老 司机 。 \n 喜欢 专研 、 思考 和 专研 遇到 的 难题 ， 不论 不论是 技术 上 还是 团队 管理 上 。 \n 对 新 技术 保持 好奇 、 热爱 和 谨慎 的 态度 。 坚信 技术 能 让 明天 更 美好 。 \n 喜欢 分享 ， 开源 追随 追随者 ， 崇尚 敏捷 开发 实践 。 \n 常用 语言   Java 、 Python 、 Golang 、 Javascript \n 目前 正在 实践   Scrum   +   看 板   +   领域 驱动 设计 （ DDD ）   +   微 服务 \n 目前 正在 学   习 机器 学习 （ ML ） 、 分布 布式 系统 分布式 分布式系统 架构 构设 设计 架构设计 、 k8s   技术 栈 \n 欢迎 一起 交流 学习 交流学习 （ 非诚 勿扰 ）       扫码 联系 我      ", "title_s": "关于   Threeq   -   出井 的 青蛙"}, {"description": "", "objectID": "https://blog.threeq.me/categories/", "tags": [], "title": "Categories", "uri": "https://blog.threeq.me/categories/", "content": "", "content_s": "", "title_s": "Categories"}, {"description": "", "objectID": "https://blog.threeq.me/tags/ci/cd/", "tags": [], "title": "Ci/Cd", "uri": "https://blog.threeq.me/tags/ci/cd/", "content": "", "content_s": "", "title_s": "Ci / Cd"}, {"description": "", "objectID": "https://blog.threeq.me/tags/css3/", "tags": [], "title": "Css3", "uri": "https://blog.threeq.me/tags/css3/", "content": "", "content_s": "", "title_s": "Css3"}, {"description": "", "objectID": "https://blog.threeq.me/tags/gerrit/", "tags": [], "title": "Gerrit", "uri": "https://blog.threeq.me/tags/gerrit/", "content": "", "content_s": "", "title_s": "Gerrit"}, {"description": "", "objectID": "https://blog.threeq.me/tags/git/", "tags": [], "title": "Git", "uri": "https://blog.threeq.me/tags/git/", "content": "", "content_s": "", "title_s": "Git"}, {"description": "", "objectID": "https://blog.threeq.me/tags/gitlab/", "tags": [], "title": "Gitlab", "uri": "https://blog.threeq.me/tags/gitlab/", "content": "", "content_s": "", "title_s": "Gitlab"}, {"description": "", "objectID": "https://blog.threeq.me/tags/gtd/", "tags": [], "title": "Gtd", "uri": "https://blog.threeq.me/tags/gtd/", "content": "", "content_s": "", "title_s": "Gtd"}, {"description": "", "objectID": "https://blog.threeq.me/tags/jenkins/", "tags": [], "title": "Jenkins", "uri": "https://blog.threeq.me/tags/jenkins/", "content": "", "content_s": "", "title_s": "Jenkins"}, {"description": "", "objectID": "https://blog.threeq.me/tags/mysql/", "tags": [], "title": "Mysql", "uri": "https://blog.threeq.me/tags/mysql/", "content": "", "content_s": "", "title_s": "Mysql"}, {"description": "", "objectID": "https://blog.threeq.me/tags/percona/", "tags": [], "title": "Percona", "uri": "https://blog.threeq.me/tags/percona/", "content": "", "content_s": "", "title_s": "Percona"}, {"description": "", "objectID": "https://blog.threeq.me/post/", "tags": [], "title": "Posts", "uri": "https://blog.threeq.me/post/", "content": "", "content_s": "", "title_s": "Posts"}, {"description": "", "objectID": "https://blog.threeq.me/tags/pt-query-digest/", "tags": [], "title": "Pt Query Digest", "uri": "https://blog.threeq.me/tags/pt-query-digest/", "content": "", "content_s": "", "title_s": "Pt   Query   Digest"}, {"description": "", "objectID": "https://blog.threeq.me/tags/redmine/", "tags": [], "title": "Redmine", "uri": "https://blog.threeq.me/tags/redmine/", "content": "", "content_s": "", "title_s": "Redmine"}, {"description": "", "objectID": "https://blog.threeq.me/tags/sql/", "tags": [], "title": "Sql", "uri": "https://blog.threeq.me/tags/sql/", "content": "", "content_s": "", "title_s": "Sql"}, {"description": "", "objectID": "https://blog.threeq.me/tags/", "tags": [], "title": "Tags", "uri": "https://blog.threeq.me/tags/", "content": "", "content_s": "", "title_s": "Tags"}, {"description": "", "objectID": "https://blog.threeq.me/", "tags": [], "title": "Threeq - 出井的青蛙", "uri": "https://blog.threeq.me/", "content": "", "content_s": "", "title_s": "Threeq   -   出井 的 青蛙"}, {"description": "", "objectID": "https://blog.threeq.me/categories/web/", "tags": [], "title": "Web", "uri": "https://blog.threeq.me/categories/web/", "content": "", "content_s": "", "title_s": "Web"}, {"description": "", "objectID": "https://blog.threeq.me/categories/%E4%B8%AA%E4%BA%BA%E7%AE%A1%E7%90%86/", "tags": [], "title": "个人管理", "uri": "https://blog.threeq.me/categories/%E4%B8%AA%E4%BA%BA%E7%AE%A1%E7%90%86/", "content": "", "content_s": "", "title_s": "个人 管理"}, {"description": "", "objectID": "https://blog.threeq.me/categories/%E5%B7%A5%E5%85%B7/", "tags": [], "title": "工具", "uri": "https://blog.threeq.me/categories/%E5%B7%A5%E5%85%B7/", "content": "", "content_s": "", "title_s": "工具"}, {"description": "", "objectID": "https://blog.threeq.me/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/", "tags": [], "title": "数据库", "uri": "https://blog.threeq.me/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/", "content": "", "content_s": "", "title_s": "数据 据库 数据库"}, {"description": "", "objectID": "https://blog.threeq.me/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/", "tags": [], "title": "数据库", "uri": "https://blog.threeq.me/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/", "content": "", "content_s": "", "title_s": "数据 据库 数据库"}, {"description": "", "objectID": "https://blog.threeq.me/tags/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/", "tags": [], "title": "时间管理", "uri": "https://blog.threeq.me/tags/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/", "content": "", "content_s": "", "title_s": "时间 管理"}, {"description": "", "objectID": "https://blog.threeq.me/tags/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/", "tags": [], "title": "查询优化", "uri": "https://blog.threeq.me/tags/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/", "content": "", "content_s": "", "title_s": "查询 优化"}]