[
{
	"uri": "https://blog.threeq.me/post/db/mysql-slow-query-analyse/",
	"title": "mysql 查询优化：慢查询分析工具 pt-query-digest",
	"tags": ["Mysql", "数据库", "查询优化", "percona", "pt-query-digest"],
	"description": "",
	"content": "在系统刚上线的时候，经常会出现慢 SQL 的情况，并且有时候系统会在特定的时间点变慢。这个时候的慢 SQL 查询语句往往是大量出现，MySQL 的慢查询日志文件也会比较大。这个时候我们往往需要从哪些查询最多、耗时最长的 sql 开始优化，以提升我们的处理效益。这个时候就需要我们能对慢日志进行统计分析，在上 M ，甚至 几十 M 的日志文件里面使用手工的方式明显是不可能的，这个时候就需要有专门的统计分析工具来帮我们做统计、分析哪些慢查询日志。percona-toolkit 就是一个提供统计和分析的工具集，这里重点介绍里面的 pt-query-digest 工具。\n\npercona-toolkit 安装 percona-toolkit 首页 文档 下载地址\nmac 安装 可以使用 brew 直接安装\nbrew install percona-toolkit  Linux 安装 详细信息参考 官方安装文档\n源码安装 # 下载源码 wget https://www.percona.com/downloads/percona-toolkit/3.0.8/source/tarball/percona-toolkit-3.0.8.tar.gz # 解压 tar xf percona-toolkit-3.0.8.tar.gz #进入目录安装 cd percona-toolkit-3.0.8 #开始编译安装 perl Makefile.PL make make install #安装完了就有命令了 ll /usr/local/bin/pt-*  pt-query-digest 基本使用 在使用 pt-query-digest 前需要有 MySQL 慢查询日志文件，这里为了大家方便实验提供了一份 MySQL 慢查询日实验数据 供大家下载测试（slow-sql-test.sql.zip 点击我下载，里面包含2018.04.01～2018.04.04 和 2018.04.06 的日志数据）。\n 查看使用帮助  \u0026gt; pt-query-digest --help   默认分析参数  \u0026gt; pt-query-digest slow-sql-test.sql   总体概要信息：\n   信息字段 说明     Exec Time 执行时间   Lock Time 锁时间   Row sent 发送行大小   Row examine 检查行大小   Query size 查询大小   Rank SQL 编号   Query ID 查询 id   Response time sql 总共执行时间 和 时间比例   Calls sql 执行次数   R/Call sql 平均每次执行时间   V/M    Item sql 类型和涉及到的表    单个 SQL 信息：\n ​ 分析结果说明：\n 分析最近一段时间内的慢查询  \u0026gt; pt-query-digest --since=12h slow-sql-test.sql # 最近 12 小时的慢查询   分析指定时间段内的慢查询  \u0026gt; pt-query-digest slow-sql-test.sql --since '2018-04-01 09:30:00' --until '2018-04-02 10:00:00'   分析还有指定特征的慢查询 SQL  \u0026gt; pt-query-digest --filter '$event-\u0026gt;{fingerprint} =~ m/^select/i' slow-sql-test.sql   分析针对某个用户的慢查询  \u0026gt; pt-query-digest --filter '($event-\u0026gt;{member} || \u0026quot;\u0026quot;) =~ m/^root/i' slow-sql-test.sql   ​  pt-query-digest进阶使用 有时候我们会遇到针对慢 SQL 进行长期的跟踪分析，这个时候我们就需要将我们的每次的分析结果进行汇总、对比分析。同时对于部分环境我们是不能直接得到慢 SQL 日志的，这个时候我们可以通过抓取 TCP 协议数据或 binlog 进行分析\n 将分析结果保存到数据库  \u0026gt; pt-query-digest --user=root –password=abc123 --review h=localhost,D=test,t=query_review--create-review-table slow-sql-test.sql   通过抓取 TCP 协议数据分析  \u0026gt; tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 \u0026gt; mysql.tcp.txt \u0026gt; pt-query-digest --type tcpdump mysql.tcp.txt\u0026gt; slow_report9.log   通过 binlog 日志分析  \u0026gt; mysqlbinlog mysql-bin.000093 \u0026gt; mysql-bin000093.sql \u0026gt; pt-query-digest --type=binlog mysql-bin000093.sql \u0026gt; slow_report10.log  单条 SQL 优化基本分析 通过上面的方法就可以找出系统里面所有的慢 SQL 语句了，并且在分析报告里面会排好序，剩下的就是我们针对每条 SQL 语句的分析调优工作了。针对 SQL 的具体优化方式内容很多，建议大家系统的学习，后面我也会写一些我常用的方法。这里说一下单条 SQL 的基础分析方法，好让大家有个开头。\n 查看 SQL 执行计划  EXPLAIN select ep_name as '企业名称', count(*) as '企业人数', FROM_UNIXTIME(ep_created/1000, GET_FORMAT(DATE,'ISO')) as '注册时间' from uc_member u left join uc_enterprise e on u.ep_id=e.ep_id where ep_domain='yq.vchangyi.com' and mem_status\u0026lt;3 group by u.ep_id order by 企业人数 desc;\t 对于上面每一列的的意义这里不再详细介绍，有兴趣的同学可以查看 MySQL 文档，或者关注我后续的文章，会有专门介绍。\n 查询 SQL 执行信息  查看 MySQL 语句执行信息需要首先开启 profiling 选线\nset profiling = 1;  然后执行完 SQL 过后使用 show profiles; 语句查看执行 SQL 的记录id\nselect ep_name as '企业名称', count(*) as '企业人数', FROM_UNIXTIME(ep_created/1000, GET_FORMAT(DATE,'ISO')) as '注册时间' from uc_member u left join uc_enterprise e on u.ep_id=e.ep_id where ep_domain='yq.vchangyi.com' and mem_status\u0026lt;3 group by u.ep_id order by 企业人数 desc; show profiles;  使用 show profile 查看 SQL 的执行信息\nshow profile ALL for query 3;  语法格式：\nshow profile [type] for query \u0026lt;query_id\u0026gt;;  如果没有指定 FOR QUERY 则显示最近一条查询的详细信息。type 是可选的，有以下几个选项：\n ALL 显示所有性能信息 BLOCK IO 显示块IO操作的次数 CONTEXT SWITCHES 显示上下文切换次数，不管是主动还是被动 CPU 显示用户CPU时间、系统CPU时间 IPC 显示发送和接收的消息数量 MEMORY [暂未实现] PAGE FAULTS 显示页错误数量 SOURCE 显示源码中的函数名称与位置 SWAPS 显示SWAP的次数 "
},
{
	"uri": "https://blog.threeq.me/post/db/mysql-sql-index-analyse-tool/",
	"title": "mysql 查询优化：索引优化",
	"tags": ["Mysql", "数据库", "查询优化"],
	"description": "",
	"content": "我们在产品中使用 MySQL 数据库的时候，肯定会用到索引的，或是在前期建立一些初始索引，或是在后期 SQL 优化的时候根据系统运行状态逐渐增加索引。不论是以什么方式建立的索引，他们都会影响我们对数据库做的操作，并且是对我们所有的数据操作都有影响，包括 增加、删除、修改、查询、统计 操作。这时如果线上有部分索引在系统升级已经失效了，我们怎么知道，怎么及时的排查和删除，需要我们持续的跟踪和分析。今天我就介绍几款针对线上数据库索引的分析工具。\n pt-index-usage userstat check-unused-keys  \n1. pt-index-usage pt-index-usage 从日志里面读取查询，并且分析它们是如何使用索引的。它需要 MySQL 的慢查询日志，在实际分析中我们可以讲 MySQL 的慢查询参数设置为 0 ，这样就可以得到所有的执行 SQL。\npt-index-uage 的安装请参考 [mysql 查询优化：慢查询分析工具 pt-query-digest]\n使用：\n\u0026gt; pt-index-usage [OPTIONS] [FILES]  分析 slow.log 的所有查询语句，并打印报告\n\u0026gt; pt-index-usage /path/to/slow.log --host localhost  不打印报告，同时把分析后的结果存入 percona 数据库\n\u0026gt; pt-index-usage slow.log --no-report --save-results-database percona  详情参考 pt-index-uage 官方文档 和 使用手册 [pt-index-uage --help]\n2. userstat MySQL 设置：\nmysql\u0026gt; SET GLOBAL userstat=ON; mysql\u0026gt; SET GLOBAL `thread_statistics`=1; mysql\u0026gt; SHOW GLOBAL VARIABLES LIKE \u0026quot;userstat\u0026quot;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | userstat | ON | +---------------+-------+ 1 row in set (0.00 sec)  查询客户端连接信息\nmysql\u0026gt; SELECT * FROM INFORMATION_SCHEMA.CLIENT_STATISTICS\\G *************************** 1. row *************************** CLIENT: 10.1.12.30 TOTAL_CONNECTIONS: 20 CONCURRENT_CONNECTIONS: 0 CONNECTED_TIME: 0 BUSY_TIME: 93 CPU_TIME: 48 BYTES_RECEIVED: 5031 BYTES_SENT: 276926 BINLOG_BYTES_WRITTEN: 217 ROWS_FETCHED: 81 ROWS_UPDATED: 0 TABLE_ROWS_READ: 52836023 SELECT_COMMANDS: 26 UPDATE_COMMANDS: 1 OTHER_COMMANDS: 145 COMMIT_TRANSACTIONS: 1 ROLLBACK_TRANSACTIONS: 0 DENIED_CONNECTIONS: 0 LOST_CONNECTIONS: 0 ACCESS_DENIED: 0 EMPTY_QUERIES: 0 TOTAL_SSL_CONNECTIONS: 0  查询索引使用信息：\nmysql\u0026gt; SELECT * FROM INFORMATION_SCHEMA.INDEX_STATISTICS WHERE TABLE_NAME='tables_priv'; +--------------+-----------------------+--------------------+-----------+ | TABLE_SCHEMA | TABLE_NAME | INDEX_NAME | ROWS_READ | +--------------+-----------------------+--------------------+-----------+ | mysql | tables_priv | PRIMARY | 2 | +--------------+-----------------------+--------------------+-----------+  查询表的使用信息：\nmysql\u0026gt; SELECT * FROM INFORMATION_SCHEMA.TABLE_STATISTICS WHERE TABLE_NAME=``tables_priv``; +--------------+-------------------------------+-----------+--------------+------------------------+ | TABLE_SCHEMA | TABLE_NAME | ROWS_READ | ROWS_CHANGED | ROWS_CHANGED_X_INDEXES | +--------------+-------------------------------+-----------+--------------+------------------------+ | mysql | tables_priv | 2 | 0 | 0 | +--------------+-------------------------------+-----------+--------------+------------------------+  具体详情请参考文档：https://www.percona.com/doc/percona-server/5.7/diagnostics/user_stats.html\n3. check-unused-keys check-unused-keys 是 Ryan Lowe 编写的基于 userstat 的一个 perl 脚本。能够比较方便输出需要删除的索引。\n下载地址：https://code.google.com/archive/p/check-unused-keys/downloads / 备份地址\nMySQL 设置：\nmysql\u0026gt; SET GLOBAL userstat=ON; mysql\u0026gt; SET GLOBAL `thread_statistics`=1; mysql\u0026gt; SHOW GLOBAL VARIABLES LIKE \u0026quot;userstat\u0026quot;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | userstat | ON | +---------------+-------+ 1 row in set (0.00 sec)  语法：\n\u0026gt; ./check-unused-keys --help  使用：\n./check-unused-keys --host=127.0.0.1 --username=root --password=toor --port=3306 --create-alter  参考：\nhttps://www.percona.com/blog/2009/06/26/check-unused-keys-a-tool-to-interact-with-index_statistics/\nhttps://www.percona.com/blog/2008/09/12/googles-user_statistics-v2-port-and-changes/\nhttps://code.google.com/archive/p/check-unused-keys/\nhttps://www.percona.com/blog/2012/12/05/quickly-finding-unused-indexes-and-estimating-their-size/\nhttps://yq.aliyun.com/articles/308518\n"
},
{
	"uri": "https://blog.threeq.me/post/git-branch-flow/",
	"title": "Git 代码库分之管理",
	"tags": ["git"],
	"description": "",
	"content": "代码版本库使用git管理，以下是git版本使用规范\n流程图说明 \n分支使用说明    分支名称 名字 说明 实例     master 线上分支 不用于开发，使用tag功能标记版本。只能由beta和hotfix合并，合并同时打上发布版本tag v1.0.2   beta 灰度分支组 灰度分之只能由test合并master产生，在测试通过后进入灰度阶段产生；灰度通过后合并进入master beta/sign   test(release) 测试分支组 只能用于测试和修改bug，只能由由master合并进feature产生。对于测试通过的test，使用merge合并方式合并master产生beta分之；合并后的release需要删除 test/sign; release/active   feature 功能分支组 从最新master检出用于开发一个新功能，一旦完成开发，合并master进入下一个test，删除本次feature分支；负责开发中多开发者代码同步使用 feature/news; feature/vote   topic 本地开发分支组 开发人员基于feature/release/hotfix检出自己本地开发(或修改bug)分支，在开发(或修改bug)中使用rebase合并方式和feature/release/hotfix进行同步。原则上一个feature/release/hotfix分支对应一个topic分支，开发完成的feature/release/hotfix删除对应的topic分支 topic/feature-news-wlp; topic/release-new-wlp; topic/hotfix-news-wlp   hotfix 修补分支组 对于线上紧急bug修改，产生一个hotfix分支，只能由master上的tag标签签出。修改完成的hotfix合并回master，并且必须删除 hotfix/v1.0.2     注意： 1. 个人开发分支除特殊情况，不允许提交到远程服务器中。\n 代码提交/合并说明 这个是开发人在日常开发中使用最多的操作。\n获取代码库 $ git clone \u0026lt;版本库地址\u0026gt; $ cd \u0026lt;代码目录\u0026gt; $ git fetch origin feature/\u0026lt;功能分支\u0026gt;:feature/\u0026lt;功能分支\u0026gt;  建立自己的本地开发分支 $ git checkout feature/\u0026lt;功能分支\u0026gt; $ git checkout -b topic/\u0026lt;功能分支\u0026gt;-\u0026lt;你的标识\u0026gt;  提交修改 $ git status $ git add . $ git commit -am '修改描述'  发布你的修改 $ git fetch origin feature/\u0026lt;功能分支\u0026gt;:feature/\u0026lt;功能分支\u0026gt; $ git rebase feature/\u0026lt;功能分支\u0026gt; # 这里可能会产生合并操作 $ git push origin topic/\u0026lt;功能分支\u0026gt;-\u0026lt;你的标识\u0026gt;:feature/\u0026lt;功能分支\u0026gt;  代码发布说明 发布代码是针对功能发布而定的，发布又分为测试发布和上线发布。对于发布操作，必须是先到测试环境(test)，再从测试环境(test)到灰度环境(beta)，最后从灰度环境(beta)到生产环境(master)，对于线上每次发布都必须有标签记录，可以回退。 原则上从beta到master只会产生 fast-forward 类型操作。以下所有操作都在自己的开发分支中完成。\n发布到测试环境 # 合并feature分支 $ git fetch origin master:master $ git fetch origin feature/\u0026lt;功能分支\u0026gt;:feature/\u0026lt;功能分支\u0026gt; $ git checkout feature/\u0026lt;功能分支\u0026gt; $ git merge master ~~解决冲突~~ # 生产test分支 $ git checkout -b test/\u0026lt;功能分支\u0026gt; $ git push origin test/\u0026lt;功能分支\u0026gt;: test/\u0026lt;功能分支\u0026gt; # 清理feature分支 $ git push origin :feature/\u0026lt;功能分支\u0026gt; $ git branch -D feature/\u0026lt;功能分支\u0026gt;  发布到灰度环境 # 合并master到测试 $ git fetch origin test/\u0026lt;功能分支\u0026gt;:test/\u0026lt;功能分支\u0026gt; $ git fetch origin master:master $ git checkout test/\u0026lt;功能分支\u0026gt; $ git merge master ~~解决冲突~~ # 生成beta分支 $ git checkout -b beta/\u0026lt;功能分支\u0026gt; $ git push origin beta/\u0026lt;功能分支\u0026gt;:beta/\u0026lt;功能名称\u0026gt; # 清理 test $ git push origin :test/\u0026lt;版本\u0026gt; $ git branch -D test/\u0026lt;版本\u0026gt;  发布到生产环境 # 合并到master $ git fetch origin beta/\u0026lt;版本\u0026gt;:beta/\u0026lt;版本\u0026gt; $ git fetch origin master:master $ git checkout master $ git merge beta/\u0026lt;版本\u0026gt; $ git tag -a \u0026lt;发布版本号\u0026gt; -m \u0026quot;发布功能描述\u0026quot; $ git push origin --tags $ git push origin master:master # 清理 beta $ git push origin :beta/\u0026lt;版本\u0026gt; $ git branch -D beta/\u0026lt;版本\u0026gt;  修改生产环境bug # 创建补丁版本，进行修改 $ git fetch origin --tag $ git checkout -b hotfix/\u0026lt;版本号\u0026gt; \u0026lt;版本号\u0026gt; # 修改完成发布 # 1. 合并到master $ git fetch origin master:master $ git checkout master $ git merge hotfix/\u0026lt;版本号\u0026gt; $ git tag -a \u0026lt;发布版本号\u0026gt; -m \u0026quot;发布功能描述\u0026quot; $ git push origin --tag $ git push origin master:master # 清理 hotfix $ git push origin :hotfix/\u0026lt;版本号\u0026gt; $ git branch -D hotfix/\u0026lt;版本号\u0026gt; "
},
{
	"uri": "https://blog.threeq.me/post/%E4%B8%AA%E4%BA%BA%E7%AE%A1%E7%90%86/gtd-flow/",
	"title": "让网络更好为我们服务",
	"tags": ["GTD", "时间管理"],
	"description": "",
	"content": "你每天早上一醒来有没有立即想拿起手机赶紧看一下（facebook、twitter、微信），无论里面有没有信息都要打开一下才安心？并且在上班之前还要想办法挤出时间看一下各大新闻网站，查收邮件在各种邮件信息中找出今天需要处理的事情。并且在工作的时候，一出现一个消息弹框马上点击进去看，害怕自己遗漏哪怕一次消息。\n这些在一个信息爆炸的时代是正常的，被称为信息饥渴。其实出现这个情况是由于我们没有很好获取信息方式和管理信息方法。这篇文章就介绍如何更好的利用网络工具来为我们管理信息。 这里我先把这些网络工具分为：\n 信息产生工具\ngithub、facebook、twitter、rss博客、linkedin、微信服务号  信息收集转换器\nzapier、ifttt、smooch、feedly、pocket、buffer  时间/任务/信息管理工具（GTD）\nEvernote、todoist、kanbanflow、自己博客、bearychat、slack    作为一个有态度的程序员肯定是从我最爱的github开始了，我们在github上面肯定少不了有自己的开源代码，当有人给我们提交一个issue、发起一个pull request等信息时我们\ngithub --\u0026gt; kanbanflow  我把看书作为一项任务来对待，在我看完一本书的时候自动在 Evernote 里面创建一个书评的待完成的笔记，并在 todolist 中建立一个任务放入到待计划中\nkanbanflow --\u0026gt; Evernote --\u0026gt; kanbanflow  对于facebook、twitter等社交工具中有新信息的时候，全部集中到 slack\nfacebook/twitter --\u0026gt; slack  对于各种新闻信息进行快速过滤，对于感兴趣的放入到pocket,同时建立阅读任务；后面在整理pocket的时候需要整理笔记的时候自动在Evernote中建立需要完善的整理笔记和相关todolit任务。\npocket --\u0026gt; todoist pocket --\u0026gt; Evernote --\u0026gt; kanbanflow  对于自己关注的新闻、博客、论坛等信息，订阅rss信息到feedly，如果有信息时自在todolist建立阅读任务；在阅读过程中需要整理笔记的时候自动在Evernote中建立需要完善的整理笔记和相关todolit任务。\nrss/feedly --\u0026gt; kanbanflow rss/feedly --\u0026gt; Evernote --\u0026gt; kanbanflow  对于自己博客更新，会自动同步到twitter、facebook等账户中，并且保存到 Evernote\n自己博客 --\u0026gt; facebook --\u0026gt; twitter --\u0026gt; Evernote  在工作中我们会用到 gitlab、jenkins 等工具，我把这些信息全都收集到 bearychat 中\ngitlab/jenkins --\u0026gt; bearychat  "
},
{
	"uri": "https://blog.threeq.me/post/ci-cd-tool/",
	"title": "项目持续集成工具",
	"tags": ["jenkins", "gerrit", "gitlab", "redmine", "CI/CD"],
	"description": "",
	"content": " 每个项目管理中都有自己的管理工具集合，这里分享一下我用过的工具集合，这里面有些工具的实践时间可能并不是很长时间，列在这里意味这下一个阶段的实践计划。同时也分享一下我自己在选择工具集合的时候考虑的点(关于每类工具如何比较它们最后做出选择我后面会慢慢补上)。在这里不会详细介绍每种工具的安装、连接和使用过程，如果后面有时间我会专门写这些工具的安装、配置和配合使用。 O 首先列出我认为在项目管理中比较重要的工具，同时这些也是我在实践中用得比较多的一套工具集：\n   工具 职责 描述     git  网上有个在线教程很好《pro git》中文版   gerrit 代码库服务器工具/代码审核工具 基于git的在线代码审查工具，围绕它建立代码审核平台和流程   gitlab 版本库展示平台 gitlab这里只作为代码展示平台和最终的发布代码库   jenkins 自动化持续集成平台 jenkins自动测试/集成/发布，围绕它建立可持续集成平台   redmine 任务管理平台/缺陷跟踪平台    sonar 代码质量报告聚合工具 围绕它搭建一个代码质量监控平台    关于上面工具的安装过程不做描述，不过个人建议可以把每个服务都做成docker容器，这样如果需要再次搭建环境就方便了。\n下面对这套工具集合的流程介绍 工具流程 整理流程 {% plantuml %} ACTOR 开发人员 control gerrit control jenkins ACTOR 审核人员 database sonar database gitlab control redmine\n开发人员-\u0026gt;gerrit: 提交代码审核 gerrit-\u0026gt;jenkins: 触发持续集成测试 jenkins-\u0026gt;jenkins: 执行集成测试 jenkins-\u0026gt;sonar: 收集代码质量报告 gerrit\u0026lt;--jenkins: 返回测试结果 gerrit-\u0026gt;审核人员: 通知人工审核 gerrit\u0026lt;--审核人员: 人工审核反馈 gerrit-\u0026gt;gerrit: 验证代码审核结果/代码合并 gerrit-\u0026gt;gitlab: 合并的代码提交到gitlab gitlab-\u0026gt;redmine: 自动更新redmine的缺陷 开发人员\u0026lt;--gerrit: 通知开发人员审核结果  {% endplantuml %}\ngerrit代码审查流程 选择工具的思考 首先要明确一点：不论多么智能的工具，都是为我们程序员服务的，只是为我们提供一个更好工作的环境，让我们可以更愉快的coding。所以在选择一个项目的基础平台环境时，一定要考虑到项目团队的人员情况。\n* 平台工具集可以引导团队成员不断提高自己 * 方便团队任务分配、跟踪 * 团队成员可以随时随地，在自己想看代码的时候方便得到 * 代码质量可视化、可跟踪 * 一切和编码不相关的内容，尽量自动化 * 可持续集成 * 方便文档的编写  同时在项目中哪些方面是需要引入工具的呢？这个答案在每一个团队都会不一样，这里写一些我自己的想法：\n* 代码管理环境 * 任务/缺陷管理环境 * 自动化测试/持续集成环境 * 代码质量监控环境 * 文档编辑环境 * 协作/沟通环境 * 集成开发环境  下面我会对这几方面的工具进行一个简单的考量，说明我自己在这方面的考虑点，但是不会做非常细致的比较，原因有2个： 1. 有很多工具我自己也没有亲身使用过； 2. 每个人或团队对工具的思考都会不同，同时网上有很多的关于它们比拼的文章，最重要的是自己的使用感受和思考\n代码管理环境 代码版本库的管理我相信这个大家都会用工具来管理（如果你还没有使用版本库管理或者还在自己手动管理，我只能呵呵。。。了）。对于不同的版本控制需求，我们需要不同的管理策略，当然这个和团队的协作方式有很大的关系。同时现在的代码版本管理工具也很多：VSS、SVN、GIT、CVS(完全可以用SVN代替)、ClearCase等。那对于代码管理环境需要考虑那些因素： * 安全性(如果你是开源的忠诚粉丝，可以完全忽略这个) * 易用性 * 总体成本 * 技术支持 * 周边产品（衍生工具/其他产品集成工具） * 是否离线操作（这个这里作为考虑条件是因为网络有时确实是一个坑,不解释） * 支持代码审查\n这里我主要比较了git和svn。VSS支持平台有限（感觉只有win）果断干掉（我不好意思让兄弟们把mac换成win吧，呵呵。。。）；ClearCase看到网上介绍感觉功能很强大的，但是看了一下价格果断干掉（原因不要深究。。。）。\nGIT git这个现在很火，用的人很多，包括我自己现在也是完全使用这个。\n 安全性\n 使用这个可以说你的代码都没有什么安全性了(一些专业的git服务器除外)，他对安全性的控制你完全可以忽略。这个也没有办法，谁让他的作者就是开源狂热份子呢 由于他们分布式管理方式，任何一个开发人员本地都有一份完整的代码库克隆，所以任何一个人员或服务器损坏了，也不会对开发有任何影响，同时找回来也是非常方便的，基本不用成本  易用性\n 这个可能就要因人而已了，如果之前对命令行的模式比较熟悉，那这个基本上就没有任何学习曲线了，只是自己的命令集合里面多了一个叫git的命令而已；但是对于之前比较习惯图形界面的童鞋就有学习成本了(实际上从我和兄弟们的使用情况来看，其实不是学习git命令花费时间，而是要让自己习惯命令行工作方式)，不过成本其实是很低的，比如我们团队的兄弟们在一周之内都实用的很溜了(这里给兄弟们赞一个)。 后面就是关于分支的管理、合并、冲突的解决等协作方面的问题，这个从我个人的使用来看问题基本不大，只要把网上的那本《pro git》跟着操作完成，你能需要遇到的问题基本OK了。 最后就是规划团队的代码管理流程了，让代码版本管理在团队不断扩大、项目越来越多的过程中不至于失控 还有一个不经常会用到的操作，就是迁移代码库。这个对于git来说就太容易了，就是2、3个命令的事  总体成本\n 因为是开源的，所以从软件费用来说是0成本 剩下的就是我们自己搭建服务器的成本了，如果感觉自己服务器也不想出，那就找网上的云服务就好了，所以这个成本也是相对叫低的了。这里列举几个我用过的：github、coding.net、Git@OSC具体谁更适合你，都去用一边就好了 最后就是团队的学习成本了，从我在易用性里面介绍，我感觉一个团队学习的成本不会超过1周 同时git的周边产品大多都是免费的或者提供免费版本，所以他的配套产品成本其实很低  技术支持\n 开源的东西就只有社区，这个不要想太多，任何东西都需要你自己去发现，当然如果你选择三方平台，他们会有服务器平台部分支持的  周边产品\n 现在基于git的衍生产品太多了，上面所列举的都是，随便baidu和google都是一大把 其他平台对于git的支持我个人感觉很不错，不论是IDE、持续集成环境、bug跟踪系统都有响应的插件支持git版本库  离线操作\n 这个离线操作也是我之前考虑使用它的一个重要原因，每个人只需要在本地编写好、提交好你的代码，然后找一个网络环境的地方，把代码同步一下就好了   SVN(有这个没有必要CVS了) svn现在用的团队很多，是一种集中式版本管理工具，我之前也是用这个很长一段时间。\n 安全性\n svn的目标就管理团队代码，所以可以很精确的控制每个人远能访问的权限，目录分支等 由于是集中式管理，所以svn服务器千万不能挂掉，如果挂了大家都不能工作了，同时找回代码也是一件费劲的事情  易用性\n svn提供图形化客户端(非linux系统)，所以大家看一下就可以使用了 svn分支、合并、冲突解决都是图形化操作，大家用起来问题不大 大家都习惯了图形操作的方式，所以学习很快 但是在团队不断变大、项目越来越多的时候，对svn的管理就需要有点技巧了  总体成本\n svn软件本身是免费的，所以软件本身费用是0成本 如果自己搭建服务器，那就需要服务器成本了，不过你可以选择网上云服务，如google代码库（国内的就别想了）、svn china、RiouxSVN等。因为我自己以前只使用过google，所以对这些云服务需要自己去体验了 团队学习我们忽略吧 svn的目标毕竟是代替老牌的cvs，周边产品的支持那是杠杠的，其他和软件开发相关的环境和平台，肯定都是支持svn的，如果你选择的基础环境工具中还有不支持svn的，那肯定是你出问题了。但是很多优秀svn的周边产品都是需要收费的  技术支持\n 社区绝对是一个神奇的存在，你遇到的问题，肯定有人解决了，至少我当时是这样的 同时可以买专业的svn产品，这样可以得到专业团队的技术支持，当然这个成本肯定是有的  周边产品\n 刚刚就说了它的目标是代替老牌的cvs，所以周边产品自然不用说，只是成本的问题  离线操作\n 这个是我当时最郁闷的一点，如果你没有网络，你就不能提交了。很不好做历史记录管理   git服务器 这里只介绍git版本库管理中其他的思考。只介绍git是因为我现在使用的git，其实是之前在使用svn的时候没有考虑那么多，自己也没有好好去研究svn的一套体系。\n要使用git作为团队代码管理，就需要git服务器（当然对那些单兵作战的兄弟们，最好也有一个git服务器，这样至少可以做到你在哪里都可以作战）。这里git服务器的选择就有两种方式了：1、使用三方托管平台；2、自己搭建git服务器。这里主要讨论第2种方式，自家搭建服务器。\ngit是基于ssh的，所以如果不要复杂功能只需要一个git-shell就可以是服务器了，不过我们可不想重复找轮子，别人已经弄好的工具，我们为什么不直接用呢！！！Gitosis、 Gitolite（这个东西的权限管理很不错）等。如果要高级功能的(如：web访问)，那gitlab和gerrit（下载需要翻墙）将是不二之选。这里我同时选用了2者，它们的不同在于gerrit是一个更偏向代码审查工具和权限控制。虽然gitlab也可以做代码审查，但是gerrit是做提交前审查，同时对代码权限的控制更细力度；而gitlab是代码提交后审查，同时必须有开发人员手动发起审查，不能自动发起审查操作。这导致他们两个的操作流程有很大区别。我个人更倾向于gerrit的方式，这样可以强迫大家把自己的代码质量提上去，所以我这里选择了两者结合，gerrit这里做权限和质量把控，gitlab做为集成测试和发布版本库。\n任务/缺陷管理环境 缺陷跟踪系统redmine、Bugzilla、BugZero、Trac、jira、trello、bugfree、禅道、coding.net等，现在不论是收费的还是免费的都有很多，我相信任何一个都能解决bug跟踪问题。从我的使用过程中发现这些系统都有各自的有点，同时也有很多不足的地方，最终一个工具是不是符合你们团队，只有试用过才知道。以下是我在使用过程中发现的一些特点，感觉如果从这些点出发去试用和思考一个系统或工具，可以很快判断这个系统或工具是否适合团队，里面有些特性是我使用过的工具里面都没有的，但是这些特点我感觉确实很有用：\n 跨平台客户端（现在大多是web，这个大部分都满足） 可以和其他种类系统集成（如：代码库，测试平台、持续集成环境等） 界面易操作性 多项目管理 自定义流程 当然成本决定算一个 系统更新速度 支持多种开发模式 分级统计功能 移动端支持  持续集成环境 持续集成环境对团队和项目的自动化有一定要求，同时可以也是对团队自动化的一种推进；同时对团队的开发流程和编码风格都会有推动作用。当然至于用什么工具那是其次的，总点是要让团队养成持续集成的习惯和节奏。\n持续集成至应该做到一下几点：\n 自动构建：要求无人值守，如果人工来操作，那就没有持续集成的必要了 发现版本库的变更：通过轮询或者定时，或者程序员使用命令，处罚持续集成发现版本库的变更 反馈机制：在出现问题时，能及时的把问题反馈给正确的人（提交者、测试者、管理者） 回滚：在出现问题后，拥有回滚到可交付的能力 纯净的构建环境：每一次都应该把之前的环境删除干净，让每一次构建都是一个新的构建 完善的集成功能：代码的测试，审查都应该做到完善。如果单纯的利用它做持续的编译，那就是大材小用了 为了避免每次过多出现问题的构建，开发者在提交代码的时候，最好在本地独立的构建一次。可以自行运行构建脚本，模拟构建 由于数据库与编码的分离，最好把数据库相关的DDL\\DML等脚本一起放入版本库中，这样CI进行构建的时候，可以连同数据库一起重新构建 能和我们的代码管理库、任务/缺陷跟踪等其他平台交互  推荐书籍《持续集成：软件质量改进和风险降低之道》\n集成工具：jenkins（前身是Hudson）、gitlab-ci、Apache Continuum、CruiseControl、Luntbuild、drone、shippable\n集成的配置是必不可少的，就是让你定义如何集成构建的构建脚本啦，如果没有一个可配置的构建过程，那持续集成从何说起呢。ant、maven、gradle、make、shell\n由于集成是基于测试之上的，所以一个好的测试工具比不可少，但是这个和团队使用的语言息息相关，每中语言都有自己的测试工具。简单举例已达到抛砖引玉的效果：各种Unit（Junit，HtmlUnit，cppUnit，SQLUnit等）、karma、mocha。。。（手软\u0026gt;_\u0026lt;）\n自动代码审查是提高代码质量，养成代码习惯比可少的，同时这些事情可以自动的做掉，可以让我们更加关注于我们的代码 checkstyle、javaNcss、PMD、siminan、jsHint、jsLint、Emma。。。\n集成反馈和报告这个可以让我们可以实时得到集成结果，失败快速找原因，成功我们就可以安心睡觉了。邮件通知、Jabber、JSCoverage、GCOV、python coverage、JCoverage、Cobertura。。。\n代码质量监控环境 代码质量监控平台其实就是让我们的代码质量可视化、可管理，让我们的代码质量形成历史记录。同时可以非常方便的工全部人员查看。\n 质量可视化 跟踪质量走向（需要历史记录） 可以自动从持续集成环境、代码审查中搜集质量信息 可以和代码管理环境打通，这个的目的是最好能看到每个人代码质量 可以和其他工程管理工具打通  SonarQube、前面介绍的自动代码审查工具\n文档编辑环境 我们的程序员往往都不喜欢写文档，你让他写文档，还不如让他写2倍的代码。但是文档确是我们项目中不可缺少的部分，那怎么让我们的程序员可以高效的写文档呢！其实我们程序员在写文档的时候，往往是被文档的格式所折磨，不能专心的写内容，从而出发对写文档的抵触情绪。所以结合以上我任务文档编写环境应该有一下几点：\n 不用关心格式，重点在内容，格式自动 能从代码中自动生成文档 文档能实时共享、自动共享，像现在用的邮件、QQ之类的其实很影响心情 文档格式足够简单，在写的时候要做到双手不脱离键盘最好  markdown、各种语言doc工具了（jsdoc、javadoc等）、wiki、shpinx\n沟通环境 上面所说的说有东西的最终目的其实都是为了解决我们协作的问题，至少是或多或少都会涉及到协作沟通问题。像现在大家用的最多的沟通工具应该变成QQ、微信之类的了吧，加上邮件、电话、各种协作平台或者其他通讯工具，但是这些工具都有一个特点：在使用的时候都会有一个长时间打断我们思维，或者需要我们专门准备一个时间去做；这些其实都会造成浪费。其实最有效的沟通就是面对面交流，所以构建一个良好的沟通环境，对我们的项目进度起着至关重要的作用：\n 沟通资源随手可得（易于获得），可以在30秒内获得 兄弟们可以采取自己认为高效的方式沟通，同时沟通方式的资源易于获得 沟通历史和结果易于记录，最好能在不察觉的情况下记录起来  项目开发环境 项目开发环境可以分为：工程管理工具和工程开发工具。项目开发环境每个团队都有差别，同时团队内部每个人肯定都有差异，因为它受到的影响因数最多，比如：使用语言，工作内容，个人习惯，操作系统，可能还和心情有关等。因此团队在选择项目开发环境的时候，既要根据团队的定位选定基础开发环境（工程管理工具），同时出一些选择辅助开发环境的选择指导规则；也要考虑每个成员的习惯，开放出来辅助开发环境，让每个成员可以根据自己的习惯，选择一套他自己最高效的项目开发环境集合。下面我列举我认为在选择工程管理工具和工程开发工具应该具备的几点特征：\n工程管理工具  可以和工程开发工具高效集成 可以测试 可以做质量检查 可以和质量管理系统集成  ant，maven，gradle，gulp，grunt，make，cmake。。。\n项目开发工具 项目开发工具也叫做集成开发环境，很多集成开发环境都带有自己的工程管理工具\n 可以和代码管理工具集成 测试必须 可以做本地质量检查 可以方便实现重构手法，关于重构推荐《重构：改变既有代码设计》 最好能和缺陷跟踪系统集成 可以和工程管理工具集成  eclipse、webstorm、vs、idea等\n需求/产品管理环境 对于需求/产品管理环境我自己现在还没有在具体项目中实践过，所以这里就不在阐述了，如果你有好的想法可以给我留言，或者给我连接地址，我连接过去\n测试管理环境 测试管理环境其实应该在持续集成环境里面，但是由于上面写持续集成环境的时候过于偏向开发人员的使用角度介绍了，并且这两套系统确实也是独立存在的。这个测试管理环境更多面向于测试人员，而我认为测试工具本身也是分为测试管理工具和测试执行工具两类别，所以我会从测试管理和测试执行两个方面来说我观点（这里的划分是按照工具的分类划分，并不是按照软件方法的方式划分），同时对于测试我想后面会有专门的一篇文章来介绍，所以这里就这样了，大家见谅我的不专业\n测试管理工具 测试管理我认为比较重要的是：测试计划，测试用例，测试跟踪，缺陷管理(这个和任务/缺陷管理环境一样)\n 可以管理测试计划 可以管理测试用例 可以跟踪每个测试用例的状态 可以和缺陷系统集成 可以和持续集成系统集成  QC(Quality Center)，TestLink，oKit，TD（TestDirector）上面提到的缺陷管理系统\n测试执行工具 测试执行的方式都很多了，并且测试执行种类也很多，比如：自动化测试，性能测试，安全测试，白盒测试等。这里面不同的测试方式所使用的工具都是不一样的：\nselenium，jmeter，jprofile，Wireshark，AppCan，Metasploit，Nmap，Acunetix，Burp Suite，apache ab，Gatling\n还是那句话工具只能给我们提供一个更专心、更快速做事的环境，但是最终这个事情能不能做成、能不能做好完全是取决我们自己。所以不论使用任何工具都行，前提是我们有自己提高的意识和习惯，比如：编码风格、编程习惯、测试习惯、重构习惯、沟通能力、协作能力等，这些才是真真决定项目成败的关键。\n"
},
{
	"uri": "https://blog.threeq.me/post/web/css3-added-selector/",
	"title": "CSS3 新增选择器",
	"tags": ["css3"],
	"description": "",
	"content": "现代前端开发中css3已经是不可其他的一部分，早已成为每个web开发人员必备技能之一。 而选择器又是css中最基础、最重要的知识点，对于我们页面结构和代码接口都有着举足轻重的作用。 今天我们就来看看css3所支持的和新增的选择器。\n\n1. CSS1定义的选择器    选择器 类型 说明     E 类型选择器 选择指定类型的元素   E#id ID选择器 选择匹配E的元素，且匹配元素的id为“id”，E选择符可以省略。   E.class 类选择器 选择匹配E的元素，且匹配元素的class属性值为“class”，E选择符可以省略。   E F 包含选择器 选择匹配F的元素，且该元素被包含在匹配E的元素内。   E:link 链接伪类选择器 选择匹配E的元素，且匹配元素被定义了超链接并未被访问。例：a:link、#a_id:link   E:visited 链接伪类选择器 选择匹配E的元素，且匹配元素被定义了超链接并已被访问。例：a:visited   E:active 用户操作伪类选择器 选择匹配E的元素，且匹配元素被激活   E:hover 用户操作伪类选择器 选择匹配E的元素，且匹配元素正被鼠标经过   E:focus 用户操作伪类选择器 选择匹配E的元素，且匹配元素获取了焦点   E:first-line 伪元素选择器 选择匹配E元素内的第一行文本   E:first-letter 伪元素选择器 选择匹配E元素内的第一个字符    2. CSS2定义的选择器    选择器 类型 说明     * 通配选择器 选择文档中所有元素   E[foo] 属性选择器 选择匹配E的元素，且该元素定义了foo属性。E选择符可以省略，表示选择定义了foo属性的任意类型的元素。   E[foo=\u0026ldquo;bar\u0026rdquo;] 属性选择器 选择匹配E的元素，且该元素foo属性值为“bar”   E[foo~=\u0026ldquo;bar\u0026rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值是一个以空格符分隔的列表，其中一个列表的值为“bar”，E选择符可以省略。   E[foo!=\u0026ldquo;en\u0026rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值是一个用连字符（-）分隔的列表，值以“en”开头。   E:first-child 结构伪类选择器 选择匹配E的元素，且该元素为父元素的第一个子元素   E:before 伪元素选择器 在匹配E的元素前面插入内容   E:after 伪元素选择器 在匹配E的元素后面插入内容   E \u0026gt; F 子包含选择器 选择匹配F的元素，且该元素为所匹配E元素的子元素。   E + F 相邻兄弟选择器 选择匹配F的元素，且该元素为所匹配E元素后面相邻的位置。   E:lang(language) 语言选择器 例如：p:lang(it) 选择带有以 \u0026ldquo;it\u0026rdquo; 开头的 lang 属性值的每个  元素。    3. CSS3新增属性选择器    选择器 类型 说明     E[foo^=\u0026ldquo;bar\u0026rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值以“bar”开始。E选择符可以省略，表示可匹配任意类型的元素。   E[foo$=\u0026ldquo;bar\u0026rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值以“bar”结束。E选择符可以省略，表示可匹配任意类型的元素。   E[foo*=\u0026ldquo;bar\u0026rdquo;] 属性选择器 选择匹配E的元素，且该元素定义了foo属性，foo属性值包含“bar”。E选择符可以省略，表示可匹配任意类型的元素。   E:root 结构伪类选择器 选择匹配E所在文档的根元素。在（X）HTML文档中，根元素就是html元素，此时该选择器与html类型选择器匹配的内容相同。   E:nth-child(n) 结构伪类选择器 选择所有在其父元素中第n个位置的匹配E的子元素。\n注意，参数n可以是数字（1、2、3）、关键字（odd、even）、公式（2n、2n+3）参数的索引从1开始。\ntr:nth-child(3)匹配所有表格中第3排的tr；\ntr:nth-child(2n+1)匹配所有表格的奇数行；\ntr:nth-child(2n)匹配所有表格的偶数行；\ntr:nth-child(odd)匹配所有表格的奇数行；\ntr:nth-child(even)匹配所有表格的偶数行；   E:nth-last-child(n) 结构伪类选择器 选择所有在其父元素中倒数第n个位置的匹配E的子元素   E:nth-of-type(n) 结构伪类选择器 选择父元素中第n个位置，且匹配E的子元素。\n注意，所有匹配E的子元素被分离出来单独排序。非E的子元素不参与排序。参数n可以是数字，关键字、公式。\n例：p:nth-of-type(1)   E:nth-last-of-type(n) 结构伪类选择器 选择父元素中倒数第n个位置，且匹配E的子元素。   E:last-child 结构伪类选择器 选择位于其父元素中最后一个位置，且匹配E的子元素。   E:first-of-type 结构伪类选择器 选择位于其父元素中且匹配E的第一个同类型的子元素。\n该选择器的功能类似于 E:nth-of-type(1)   E:last-of-type 结构伪类选择器 选择位于其父元素中且匹配E的最后第一个同类型的子元素。\n该选择器的功能类似于 E:nth-last-of-type(1)   E:only-child 结构伪类选择器 选择其父元素只包含一个子元素，且该子元素匹配E。   E:only-of-type 结构伪类选择器 选择其父元素只包含一个同类型的子元素，且该子元素匹配E。   E:empty 结构伪类选择器 选择匹配E的元素，且该元素不包含子节点   E:enabled UI状态伪类选择器 选择匹配E的所有可用UI元素。   E:disabled UI状态伪类选择器 选择匹配E的所有不可用UI元素。   E:checked UI状态伪类选择器 选择匹配E的所有可用UI元素。\n例：input:checked匹配input type为radio及checkbox元素   ::selection UI状态伪类选择器 选择被用户选取的元素部分。   E ~ F 相邻兄弟选择器 选择匹配F的所有元素，且匹配元素位于匹配E的元素后面。在DOM结构树中，E和F所匹配的元素应该在同一级结构上。   E:not(s) 否定伪类选择器 选择匹配E的所有元素，且过滤掉匹配s选择符的任意元素。s是一个简单结构的选择器，不能使用符合选择器，   E:target 目标伪类选择器 选择匹配E的所有元素，且匹配元素被相关URL指向。\n注意：该选择器是动态选择器，只有存在URL指向该匹配元素时，样式才起效果。\n例：demo.html#id    参考：http://www.w3school.com.cn/cssref/css_selectors.asp\n"
},
{
	"uri": "https://blog.threeq.me/about/",
	"title": "关于 Threeq - 出井的青蛙",
	"tags": [],
	"description": "Threeq - 出井的青蛙介绍",
	"content": " Threeq - 出井的青蛙  快乐的程序员、老司机。\n喜欢专研、思考和专研遇到的难题，不论是技术上还是团队管理上。\n对新技术保持好奇、热爱和谨慎的态度。坚信技术能让明天更美好。\n喜欢分享，开源追随者，崇尚敏捷开发实践。\n常用语言 Java、Python、Golang、Javascript\n目前正在实践 Scrum + 看板 + 领域驱动设计（DDD） + 微服务\n目前正在学 习机器学习（ML）、分布式系统架构设计、k8s 技术栈\n欢迎一起交流学习（非诚勿扰）   扫码联系我   "
},
{
	"uri": "https://blog.threeq.me/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/ci/cd/",
	"title": "Ci/Cd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/css3/",
	"title": "Css3",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/gerrit/",
	"title": "Gerrit",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/git/",
	"title": "Git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/gitlab/",
	"title": "Gitlab",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/gtd/",
	"title": "Gtd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/jenkins/",
	"title": "Jenkins",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/mysql/",
	"title": "Mysql",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/percona/",
	"title": "Percona",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/post/",
	"title": "Posts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/pt-query-digest/",
	"title": "Pt Query Digest",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/redmine/",
	"title": "Redmine",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/",
	"title": "Threeq - 出井的青蛙",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/categories/web/",
	"title": "Web",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/categories/%E4%B8%AA%E4%BA%BA%E7%AE%A1%E7%90%86/",
	"title": "个人管理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/categories/%E5%B7%A5%E5%85%B7/",
	"title": "工具",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/",
	"title": "数据库",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/",
	"title": "数据库",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/",
	"title": "时间管理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.threeq.me/tags/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/",
	"title": "查询优化",
	"tags": [],
	"description": "",
	"content": ""
}]